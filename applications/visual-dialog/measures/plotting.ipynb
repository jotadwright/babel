{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Specify directory that contains files with measures\n",
    "dir = \"/Users/laraverheyen/Projects/Babel3/applications/visual-dialog/measures/data/\"\n",
    "\n",
    "names = joinNodenames(dir)\n",
    "fcg_questions = fcg_measures(\"QUESTIONS-INTRODUCED-BY-GRAMMAR.csv\")\n",
    "fcg_answers = fcg_measures(\"QUESTIONS-SOLVED-BY-GRAMMAR.csv\")\n",
    "#irl_answers = irl_measures(\"QUESTIONS-SOLVED-BY-MENTAL-SIMULATION.csv\")\n",
    "irl_answers_initial = irl_measures(\"INITIAL.csv\")\n",
    "irl_answers_discourse = irl_measures(\"DISCOURSE.csv\")\n",
    "irl_answers_perception = irl_measures(\"PERCEPTION.csv\")\n",
    "irl_answers_inference = irl_measures(\"INFERENCE.csv\")\n",
    "\n",
    "#answers = combine_lists([fcg_answers, irl_answers])\n",
    "answers = combine_lists([fcg_answers, irl_answers_initial, irl_answers_discourse, irl_answers_perception, irl_answers_inference])\n",
    "plot_lines(fcg_questions, answers)\n",
    "\n",
    "plot_stackplot(fcg_questions, 'questions', [fcg_answers, irl_answers_initial, irl_answers_discourse, irl_answers_perception, irl_answers_inference], ['answers from language', 'answers initial', 'answers from discourse', 'answers from perception', 'answers from inference'])\n",
    "\n",
    "#total_answers = combine_lists([fcg_answers, irl_answers])\n",
    "unsolved_questions = subtract_lists([cumSum(answers), cumSum(fcg_questions)])\n",
    "plot_pies([cumSum(fcg_answers), cumSum(irl_answers_initial) , cumSum(irl_answers_discourse), cumSum(irl_answers_perception), cumSum(irl_answers_inference), unsolved_questions], ['answers from language', 'answers initial', 'answers from discourse', 'answers from perception', 'answers from inference', 'remaining questions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pies(values, labels): \n",
    "\n",
    "    for i in range(0, len(values[0]), 10): \n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(10.5, 13.5)\n",
    "        \n",
    "        vals = [val[i] for val in values]\n",
    "        \n",
    "        ax.pie(vals, labels=None,autopct='%1.1f%%',  textprops={'fontsize': 30})\n",
    "        ax.axis('equal')\n",
    "        plt.legend(labels=labels,prop={'size': 20},loc='lower left')\n",
    "\n",
    "        plt.savefig(\"pie-after-instructions-\" + str(i) + \".pdf\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stackplot(line_numbers, line_label, stack_numbers, stack_labels): \n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    \n",
    "    cumline = cumSum(line_numbers)\n",
    "    vals = [x for x in range(0, len(stack_numbers[0]))]\n",
    "    total = []\n",
    "    for number in stack_numbers: \n",
    "        total.append(cumSum(number))\n",
    "    \n",
    "    ax.stackplot(vals, total, labels=stack_labels, alpha=0.8)\n",
    "\n",
    "    ax.plot(cumline, label=line_label,color=\"black\", linewidth=1.5)\n",
    "    \n",
    "    plt.xticks([])\n",
    "\n",
    "    ax.set_ylabel('Number of questions')\n",
    "    ax.set_xlabel('Steps in recipe execution')\n",
    "    ax.legend(prop={\"size\":20})\n",
    "    ax.yaxis.label.set_fontsize(20)\n",
    "    ax.xaxis.label.set_fontsize(20)\n",
    "    plt.yticks(fontsize=15)\n",
    "    \n",
    "    plt.savefig('measures_stackplot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lines(questions, answers):\n",
    "\n",
    "    questions = cumSum(questions)\n",
    "    answers = cumSum(answers)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "    ax.plot(questions, label='Number of questions',color=\"black\", linewidth=1.5)\n",
    "    ax.plot(answers, label='Number of answers',color=\"red\", linewidth=1.5)\n",
    "    \n",
    "    plt.xticks([])\n",
    "    ax.set_ylabel('Number of questions')\n",
    "    ax.set_xlabel('Steps in dialog')\n",
    "    ax.legend(prop={\"size\":20})\n",
    "    ax.yaxis.label.set_fontsize(20)\n",
    "    ax.xaxis.label.set_fontsize(20)\n",
    "    plt.yticks(fontsize=15)\n",
    "\n",
    "    plt.savefig('measures_line_plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions to read measures from files \n",
    "## if you give measures from IRL, it will also append fcg measures 0 to it and the other way around.\n",
    "\n",
    "def fcg_measures(measures_file): \n",
    "    fcg_measures_file = os.path.join(dir, measures_file)\n",
    "    irl_names_file = os.path.join(dir, \"irl-nodenames.csv\")\n",
    "    \n",
    "    fcg_file = open(fcg_measures_file)\n",
    "    fcg_measures = csv.reader(fcg_file, delimiter=' ')\n",
    "    irl_file = open(irl_names_file)\n",
    "    irl_names = csv.reader(irl_file, delimiter=' ')\n",
    "    \n",
    "    all_measures = []\n",
    "    for fcg_measure, irl_name in zip(fcg_measures, irl_names):\n",
    "        fcg_measure_int = [int(x) for x in fcg_measure]\n",
    "        all_measures.append(fcg_measure_int)\n",
    "        irl_measure = [0] * len(irl_name)\n",
    "        all_measures.append(irl_measure)\n",
    "    return flatten(all_measures)\n",
    "\n",
    "def irl_measures(measures_file): \n",
    "    fcg_names_file = os.path.join(dir, \"fcg-nodenames.csv\")\n",
    "    irl_measures_file = os.path.join(dir, measures_file)\n",
    "    \n",
    "    fcg_file = open(fcg_names_file)\n",
    "    fcg_names = csv.reader(fcg_file, delimiter=' ')\n",
    "    irl_file = open(irl_measures_file)\n",
    "    irl_measures = csv.reader(irl_file, delimiter=' ')\n",
    "    \n",
    "    all_measures = []\n",
    "    for fcg_name, irl_measure in zip(fcg_names, irl_measures):\n",
    "        fcg_measure = [0] * len(fcg_name)\n",
    "        all_measures.append(fcg_measure)\n",
    "        irl_measure_int = [int(x) for x in irl_measure]\n",
    "        all_measures.append(irl_measure_int)\n",
    "    return flatten(all_measures)\n",
    "\n",
    "# Put together nodenames from FCG and IRL\n",
    "def joinNodenames(dir):\n",
    "    fcg_names_file = os.path.join(dir, \"fcg-nodenames.csv\")\n",
    "    irl_names_file = os.path.join(dir, \"irl-nodenames.csv\")\n",
    "    \n",
    "    fcg_file = open(fcg_names_file)\n",
    "    fcg_names = csv.reader(fcg_file, delimiter=' ')\n",
    "    irl_file = open(irl_names_file)\n",
    "    irl_names = csv.reader(irl_file, delimiter=' ')\n",
    "    \n",
    "    all_nodenames = []\n",
    "    for fcg_name, irl_name in zip(fcg_names, irl_names):\n",
    "        all_nodenames.append(fcg_name)\n",
    "        all_nodenames.append(irl_name)\n",
    "        \n",
    "    return flatten(all_nodenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UTILS\n",
    "def cumSum(s):\n",
    "   sm=0\n",
    "   cum_list=[]\n",
    "   for i in s:\n",
    "      sm=sm+i\n",
    "      cum_list.append(sm)\n",
    "   return cum_list\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def combine_lists(lists):\n",
    "    all_lists = [0] * len(lists[0])\n",
    "    for list in lists: \n",
    "        all_lists = [sum(i) for i in zip(list, all_lists)]\n",
    "    return all_lists\n",
    "\n",
    "def subtract_lists(lists):\n",
    "    all_lists = [0] * len(lists[0])\n",
    "    for list in lists:\n",
    "        all_lists = [(i - j) for i,j in zip(list, all_lists)]\n",
    "    return all_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stacked_bars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_remaining_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_cumulative_list(cum_lst, greatest_el): \n",
    "    norm_cum_list = []\n",
    "    for el in cum_lst: \n",
    "        norm_cum_list.append(el/greatest_el)\n",
    "    return norm_cum_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### these pies \n",
    "\n",
    "data_dir = \"data-for-python-whole/\"\n",
    "irl_filenames = ['irl-nodenames.csv','RECORD-ANCHORING-MICRO.csv', 'RECORD-QUESTIONS-IRL.csv', 'RECORD-SET-SLOTS.csv' , 'RECORD-SLOTS.csv']\n",
    "fcg_filenames = ['fcg-nodenames.csv','RECORD-VARIABLES-BOUND-BY-GRAMMAR-MICRO.csv', 'RECORD-VARIABLES-INTRODUCED-BY-GRAMMAR-MICRO.csv','RECORD-ACCESSIBLE-ENTITIES-BOUND-BY-GRAMMAR-MICRO.csv']\n",
    "dicts = files_to_dict(data_dir, irl_filenames, fcg_filenames)\n",
    "dict_fcg = dicts[0]\n",
    "dict_irl = dicts[1]\n",
    "dict_irl = fix_length_aes(dict_irl)\n",
    "final_d = combine_irl_and_fcg(dict_fcg,dict_irl)\n",
    "\n",
    "flattened_dictionary = {}\n",
    "\n",
    "for key in final_d.keys():\n",
    "    regular_list = final_d[key]\n",
    "    lst = [item for sublist in regular_list for item in sublist]\n",
    "    flattened_dictionary[key] = lst \n",
    "\n",
    "node_names = flattened_dictionary['nodenames']\n",
    "introduced_vars = cumSum([int(item) for item in flattened_dictionary['introduced_vars']])\n",
    "bound_vars_fcg = cumSum([int(item) for item in flattened_dictionary['bound_vars_fcg']])\n",
    "bound_aes_fcg = cumSum([int(item) for item in flattened_dictionary['bound_aes_fcg']])\n",
    "bound_vars_irl = cumSum([int(item) for item in flattened_dictionary['bound_vars_irl']])\n",
    "bound_slots_irl = cumSum([int(item) for item in flattened_dictionary['bound_slots_irl']])\n",
    "\n",
    "lst = []\n",
    "for i in range(0,len(bound_vars_fcg)):\n",
    "    lst.append(i)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#fig.set_size_inches(5,5)\n",
    "plt.figure(figsize = (5, 15))\n",
    "\n",
    "explode = (0, 0, 0, 0, 0.1) \n",
    "x = [61,74,87,96,111,117,131,len(introduced_vars)-1]\n",
    "#i = 0\n",
    "def update(i): \n",
    "#for x in [61,111,len(introduced_vars)-1]:\n",
    "    ax.clear()\n",
    "    ax.axis('equal')\n",
    "    total = sum(introduced_vars[:x[i]])\n",
    "    bound_vars = {'Answers from language': sum(bound_vars_fcg[:x[i]]), \n",
    "                 'Answers from mental simulation': sum(bound_vars_irl[:x[i]]), \n",
    "                 'Answers from ontology' : sum(bound_slots_irl[:x[i]]), \n",
    "                 'Answers from discourse model': sum(bound_aes_fcg[:x[i]]),\n",
    "                 'Remaining questions': total - sum(bound_vars_fcg[:x[i]]) - sum(bound_vars_irl[:x[i]]) - sum(bound_slots_irl[:x[i]]) - sum(bound_aes_fcg[:x[i]])}\n",
    "    ax.pie(bound_vars.values(), explode=explode, labels=None,autopct='%1.1f%%', textprops={'fontsize': 10})\n",
    "    \n",
    "    ax.set_title(\"{}\".format(recipe[i]))\n",
    "ani = FuncAnimation(fig, update, frames=range(8),  repeat=False)\n",
    "\n",
    "f = \"questions-solved-compared-to-questions-introduced.gif\" \n",
    "ani.save(f, fps=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "animate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### these pies are cumulative\n",
    "\n",
    "data_dir = \"data-for-python-whole/\"\n",
    "irl_filenames = ['irl-nodenames.csv','RECORD-ANCHORING-MICRO.csv', 'RECORD-QUESTIONS-IRL.csv', 'RECORD-SET-SLOTS.csv' , 'RECORD-SLOTS.csv']\n",
    "fcg_filenames = ['fcg-nodenames.csv','RECORD-VARIABLES-BOUND-BY-GRAMMAR-MICRO.csv', 'RECORD-VARIABLES-INTRODUCED-BY-GRAMMAR-MICRO.csv','RECORD-ACCESSIBLE-ENTITIES-BOUND-BY-GRAMMAR-MICRO.csv']\n",
    "dicts = files_to_dict(data_dir, irl_filenames, fcg_filenames)\n",
    "dict_fcg = dicts[0]\n",
    "dict_irl = dicts[1]\n",
    "dict_irl = fix_length_aes(dict_irl)\n",
    "final_d = combine_irl_and_fcg(dict_fcg,dict_irl)\n",
    "\n",
    "flattened_dictionary = {}\n",
    "\n",
    "for key in final_d.keys():\n",
    "    regular_list = final_d[key]\n",
    "    lst = [item for sublist in regular_list for item in sublist]\n",
    "    flattened_dictionary[key] = lst \n",
    "\n",
    "node_names = flattened_dictionary['nodenames']\n",
    "introduced_vars = cumSum([int(item) for item in flattened_dictionary['introduced_vars']])\n",
    "bound_vars_fcg = cumSum([int(item) for item in flattened_dictionary['bound_vars_fcg']])\n",
    "bound_aes_fcg = cumSum([int(item) for item in flattened_dictionary['bound_aes_fcg']])\n",
    "bound_vars_irl = cumSum([int(item) for item in flattened_dictionary['bound_vars_irl']])\n",
    "bound_slots_irl = cumSum([int(item) for item in flattened_dictionary['bound_slots_irl']])\n",
    "\n",
    "\n",
    "bound_vars = {'Answers from language': 0, \n",
    "                 'Answers from mental simulation': 0, \n",
    "                 'Answers from ontology' :0, \n",
    "                 'Answers from discourse model': 0,\n",
    "                 'Remaining questions': 0}\n",
    "    \n",
    "\n",
    "lst = []\n",
    "for i in range(0,len(bound_vars_fcg)):\n",
    "    lst.append(i)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#fig.set_size_inches(5,5)\n",
    "plt.figure(figsize = (5, 15))\n",
    "\n",
    "explode = (0, 0, 0, 0, 0.1) \n",
    "x = [61,74,87,96,111,117,131,len(introduced_vars)]\n",
    "#i = 0\n",
    "\n",
    "def update(i): \n",
    "#for x in [61,111,len(introduced_vars)-1]:\n",
    "    ax.clear()\n",
    "    #ax.axis('equal')\n",
    "    #total = sum(introduced_vars[:x[i]])\n",
    "    total = sum(introduced_vars[:x[i]])\n",
    "    radius = sum(introduced_vars[:x[i]]) / sum(introduced_vars)\n",
    "    print(radius)\n",
    "    bound_vars = {'Answers from language': sum(bound_vars_fcg[:x[i]]), \n",
    "                 'Answers from mental simulation': sum(bound_vars_irl[:x[i]]), \n",
    "                'Answers from ontology' : sum(bound_slots_irl[:x[i]]), \n",
    "                 'Answers from discourse model': sum(bound_aes_fcg[:x[i]]),\n",
    "                 'Remaining questions': total - sum(bound_vars_fcg[:x[i]]) - sum(bound_vars_irl[:x[i]]) -sum(bound_slots_irl[:x[i]]) - sum(bound_aes_fcg[:x[i]])}\n",
    "    \n",
    "    ax.pie(bound_vars.values(), explode=None, labels=None,autopct='%1.1f%%', radius=radius, textprops={'fontsize': 10})\n",
    "    \n",
    "    ax.set_title(\"{}\".format(recipe[i]))\n",
    "    #if x == 61:\n",
    "    ax.legend(labels = bound_vars.keys(), loc=\"upper left\")\n",
    "\n",
    "    print(\"{}\".format(recipe[i]))\n",
    "\n",
    "#plt.legend(labels=bound_vars.keys(),loc='upper left')\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=range(8),  repeat=False)\n",
    "f = \"test-cumulative.gif\" \n",
    "ani.save(f, fps=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### these pies \n",
    "\n",
    "data_dir = \"data-for-python-whole/\"\n",
    "irl_filenames = ['irl-nodenames.csv','RECORD-ANCHORING-MICRO.csv', 'RECORD-QUESTIONS-IRL.csv', 'RECORD-SET-SLOTS.csv' , 'RECORD-SLOTS.csv']\n",
    "fcg_filenames = ['fcg-nodenames.csv','RECORD-VARIABLES-BOUND-BY-GRAMMAR-MICRO.csv', 'RECORD-VARIABLES-INTRODUCED-BY-GRAMMAR-MICRO.csv','RECORD-ACCESSIBLE-ENTITIES-BOUND-BY-GRAMMAR-MICRO.csv']\n",
    "dicts = files_to_dict(data_dir, irl_filenames, fcg_filenames)\n",
    "dict_fcg = dicts[0]\n",
    "dict_irl = dicts[1]\n",
    "dict_irl = fix_length_aes(dict_irl)\n",
    "final_d = combine_irl_and_fcg(dict_fcg,dict_irl)\n",
    "\n",
    "flattened_dictionary = {}\n",
    "\n",
    "for key in final_d.keys():\n",
    "    regular_list = final_d[key]\n",
    "    lst = [item for sublist in regular_list for item in sublist]\n",
    "    flattened_dictionary[key] = lst \n",
    "\n",
    "node_names = flattened_dictionary['nodenames']\n",
    "introduced_vars = [int(item) for item in flattened_dictionary['introduced_vars']]\n",
    "bound_vars_fcg = [int(item) for item in flattened_dictionary['bound_vars_fcg']]\n",
    "bound_aes_fcg = [int(item) for item in flattened_dictionary['bound_aes_fcg']]\n",
    "bound_vars_irl = [int(item) for item in flattened_dictionary['bound_vars_irl']]\n",
    "bound_slots_irl = [int(item) for item in flattened_dictionary['bound_slots_irl']]\n",
    "\n",
    "\n",
    "\n",
    "bound_vars = {'Answers from language': 0, \n",
    "              'Answers from mental simulation': 0, \n",
    "                 'Answers from ontology' :0, \n",
    "                 'Answers from discourse model': 0,\n",
    "                 'Remaining questions': 0}\n",
    "    \n",
    "\n",
    "lst = []\n",
    "for i in range(0,len(bound_vars_fcg)):\n",
    "    lst.append(i)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.figure(figsize = (5, 15))\n",
    "\n",
    "explode = (0, 0, 0, 0, 0.1) \n",
    "x = [61,74,87,96,111,117,131,len(introduced_vars)]\n",
    "#i = 0\n",
    "\n",
    "def update(i): \n",
    "    ax.clear()\n",
    "    print(x[i-1])\n",
    "    total = sum(introduced_vars[x[i-1]:x[i]])\n",
    "    bound_vars = {'Answers from language': sum(bound_vars_fcg[x[i-1]:x[i]]), \n",
    "                  'Answers from mental simulation': sum(bound_vars_irl[x[i-1]:x[i]]), \n",
    "                  'Answers from ontology' : sum(bound_slots_irl[x[i-1]:x[i]]), \n",
    "                  'Answers from discourse model': sum(bound_aes_fcg[x[i-1]:x[i]]),\n",
    "                  'Remaining questions': total - sum(bound_vars_fcg[x[i-1]:x[i]]) - sum(bound_vars_irl[x[i-1]:x[i]]) -sum(bound_slots_irl[x[i-1]:x[i]]) - sum(bound_aes_fcg[x[i-1]:x[i]])}\n",
    "    \n",
    "    ax.pie(bound_vars.values(), explode=None, labels=None,autopct='%1.1f%%', radius=1, textprops={'fontsize': 10})\n",
    "    \n",
    "    ax.set_title(\"{}\".format(recipe[i]))\n",
    "   # ax.legend(labels = bound_vars.keys(), loc=\"lower right\")\n",
    "\n",
    "    print(\"{}\".format(recipe[i]))\n",
    "\n",
    "#plt.legend(labels=bound_vars.keys(),loc='lower right')\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=range(8),  repeat=False)\n",
    "f = \"test.gif\" \n",
    "ani.save(f, fps=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### these pies are cumulative\n",
    "\n",
    "data_dir = \"data-for-python/\"\n",
    "irl_filenames = ['irl-nodenames.csv','RECORD-ANCHORING-MICRO.csv', 'RECORD-QUESTIONS-IRL.csv', 'RECORD-SET-SLOTS.csv' , 'RECORD-SLOTS.csv']\n",
    "fcg_filenames = ['fcg-nodenames.csv','RECORD-VARIABLES-BOUND-BY-GRAMMAR-MICRO.csv', 'RECORD-VARIABLES-INTRODUCED-BY-GRAMMAR-MICRO.csv','RECORD-ACCESSIBLE-ENTITIES-BOUND-BY-GRAMMAR-MICRO.csv']\n",
    "dicts = files_to_dict(data_dir, irl_filenames, fcg_filenames)\n",
    "dict_fcg = dicts[0]\n",
    "dict_irl = dicts[1]\n",
    "dict_irl = fix_length_aes(dict_irl)\n",
    "final_d = combine_irl_and_fcg(dict_fcg,dict_irl)\n",
    "\n",
    "flattened_dictionary = {}\n",
    "\n",
    "for key in final_d.keys():\n",
    "    regular_list = final_d[key]\n",
    "    lst = [item for sublist in regular_list for item in sublist]\n",
    "    flattened_dictionary[key] = lst \n",
    "\n",
    "node_names = flattened_dictionary['nodenames']\n",
    "print(node_names)\n",
    "introduced_vars = cumSum([int(item) for item in flattened_dictionary['introduced_vars']])\n",
    "bound_vars_fcg = cumSum([int(item) for item in flattened_dictionary['bound_vars_fcg']])\n",
    "bound_aes_fcg = cumSum([int(item) for item in flattened_dictionary['bound_aes_fcg']])\n",
    "bound_vars_irl = cumSum([int(item) for item in flattened_dictionary['bound_vars_irl']])\n",
    "bound_slots_irl = cumSum([int(item) for item in flattened_dictionary['bound_slots_irl']])\n",
    "\n",
    "\n",
    "bound_vars = {'Answers from language': 0, \n",
    "                 'Answers from mental simulation': 0, \n",
    "                 'Answers from ontology' :0, \n",
    "                 'Answers from discourse model': 0,\n",
    "                 'Remaining questions': 0}\n",
    "    \n",
    "\n",
    "lst = []\n",
    "for i in range(0,len(bound_vars_fcg)):\n",
    "    lst.append(i)\n",
    "\n",
    "\n",
    "recipe = [\"Ingredients\", #226 grams butter, room temperature. 116 grams sugar. \\n4 grams vanilla extract, 4 grams almond extract, 340 grams flour, \\n112 grams almond flour, and 29 grams powdered sugar\", \n",
    "\"Beat the butter and the sugar together until light and fluffy.\",\n",
    "\"Add the vanilla and almond extracts and mix.\",\n",
    "\"Add the flour and the almond flour. \",\n",
    "\"Mix thoroughly.\",\n",
    "\"Take generous tablespoons of the dough and roll it into a small ball, \\nabout an inch in diameter, and then shape it into a crescent shape.\",\n",
    "\"Place onto a parchment paper lined baking sheet.\",\n",
    "\"Bake at 175 degrees Celsius for 15 - 20 minutes. \",\n",
    "\"Dust with powdered sugar.\"]\n",
    " \n",
    "x = [61,74,87,96,111,117,131,len(introduced_vars)]\n",
    "#i = 0\n",
    "\n",
    "for x in [61,74,87,96,111,117,131,len(introduced_vars)]:\n",
    "#for x in [61,111,len(introduced_vars)-1]:\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(5,5)\n",
    "    #plt.figure(figsize = (15, 15))\n",
    "    explode = (0, 0, 0, 0, 0.1)\n",
    "    #ax.clear()\n",
    "    #ax.axis('equal')\n",
    "    #total = sum(introduced_vars[:x[i]])\n",
    "    total = sum(introduced_vars[:x])\n",
    "    radius = sum(introduced_vars[:x]) / sum(introduced_vars)\n",
    "    print(radius)\n",
    "    bound_vars = {'Answers from language': sum(bound_vars_fcg[:x]), \n",
    "                 'Answers from mental simulation': sum(bound_vars_irl[:x]), \n",
    "                'Answers from ontology' : sum(bound_slots_irl[:x]), \n",
    "                 'Answers from discourse model': sum(bound_aes_fcg[:x]),\n",
    "                 'Remaining questions': total - sum(bound_vars_fcg[:x]) - sum(bound_vars_irl[:x]) - sum(bound_slots_irl[:x]) - sum(bound_aes_fcg[:x])}\n",
    "    \n",
    "    if x == 61:\n",
    "        pctdistance = 1.5\n",
    "    else:\n",
    "        pctdistance = 0.6\n",
    "    \n",
    "    ax.pie(bound_vars.values(), explode=None, labels=None,  pctdistance =pctdistance, autopct='%1.1f%%', radius=radius, textprops={'fontsize': 10})\n",
    "    \n",
    "    if x == 61: \n",
    "        ax.legend(labels=bound_vars.keys(),prop={'size': 10},loc='upper left')\n",
    "        \n",
    "    plt.savefig('pie-chart-' + str(x) + '.pdf' , bbox_inches='tight')\n",
    "    \n",
    "\n",
    "#plt.legend(labels=bound_vars.keys(),loc='upper left')\n",
    "    plt.show()\n",
    "#ani = FuncAnimation(fig, update, frames=range(8),  repeat=False)\n",
    "#f = \"test-cumulative.gif\" \n",
    "#ani.save(f, fps=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b92396f9b56f1350fabc55aa1a1105a84f42df9046600cf5093bdb969faef3c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
