{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########start hier --> werkt nog niet\n",
    "def plot_pies():\n",
    "    data_dir = \"data/\"\n",
    "    irl_filenames = ['irl-nodenames.csv','QUESTIONS-INTRODUCED-BY-DISCOURSE.csv', 'QUESTIONS-INTRODUCED-BY-ONTOLOGY.csv', 'QUESTIONS-INTRODUCED-BY-MENTAL-SIMULATION.csv' , 'QUESTIONS-SOLVED-BY-MENTAL-SIMULATION.csv', 'QUESTIONS-SOLVED-BY-ONTOLOGY.csv']\n",
    "    fcg_filenames = ['fcg-nodenames.csv','QUESTIONS-INTRODUCED-BY-GRAMMAR.csv', 'QUESTIONS-SOLVED-BY-GRAMMAR.csv', 'QUESTIONS-SOLVED-BY-DISCOURSE.csv']\n",
    "    dicts = files_to_dict(data_dir, irl_filenames, fcg_filenames)\n",
    "    result = combine_irl_and_fcg(dicts[0], dicts[1], True)\n",
    "    plot_measures_pie(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########start hier --> werkt nog niet\n",
    "def plot_stackplot():\n",
    "    data_dir = \"data/\"\n",
    "    irl_filenames = ['irl-nodenames.csv','QUESTIONS-INTRODUCED-BY-DISCOURSE.csv', 'QUESTIONS-INTRODUCED-BY-ONTOLOGY.csv', 'QUESTIONS-INTRODUCED-BY-MENTAL-SIMULATION.csv' , 'QUESTIONS-SOLVED-BY-MENTAL-SIMULATION.csv', 'QUESTIONS-SOLVED-BY-ONTOLOGY.csv']\n",
    "    fcg_filenames = ['fcg-nodenames.csv','QUESTIONS-INTRODUCED-BY-GRAMMAR.csv', 'QUESTIONS-SOLVED-BY-GRAMMAR.csv', 'QUESTIONS-SOLVED-BY-DISCOURSE.csv']\n",
    "    dicts = files_to_dict(data_dir, irl_filenames, fcg_filenames)\n",
    "    result = combine_irl_and_fcg(dicts[0], dicts[1], None)\n",
    "    plot_measures_stackplot(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########start hier --> werkt nog niet\n",
    "def plot_stackplot_introduced():\n",
    "    data_dir = \"data/\"\n",
    "    irl_filenames = ['irl-nodenames.csv','QUESTIONS-INTRODUCED-BY-DISCOURSE.csv', 'QUESTIONS-INTRODUCED-BY-ONTOLOGY.csv', 'QUESTIONS-INTRODUCED-BY-MENTAL-SIMULATION.csv' , 'QUESTIONS-SOLVED-BY-MENTAL-SIMULATION.csv', 'QUESTIONS-SOLVED-BY-ONTOLOGY.csv']\n",
    "    fcg_filenames = ['fcg-nodenames.csv','QUESTIONS-INTRODUCED-BY-GRAMMAR.csv', 'QUESTIONS-SOLVED-BY-GRAMMAR.csv', 'QUESTIONS-SOLVED-BY-DISCOURSE.csv']\n",
    "    dicts = files_to_dict(data_dir, irl_filenames, fcg_filenames)\n",
    "    result = combine_irl_and_fcg(dicts[0], dicts[1], None)\n",
    "    plot_measures_stackplot_questions(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stackplot_introduced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########start hier --> werkt nog niet\n",
    "def plot_stacked_bars():\n",
    "    data_dir = \"data/\"\n",
    "    irl_filenames = ['irl-nodenames.csv','QUESTIONS-INTRODUCED-BY-DISCOURSE.csv', 'QUESTIONS-INTRODUCED-BY-ONTOLOGY.csv', 'QUESTIONS-INTRODUCED-BY-MENTAL-SIMULATION.csv' , 'QUESTIONS-SOLVED-BY-MENTAL-SIMULATION.csv', 'QUESTIONS-SOLVED-BY-ONTOLOGY.csv']\n",
    "    fcg_filenames = ['fcg-nodenames.csv','QUESTIONS-INTRODUCED-BY-GRAMMAR.csv', 'QUESTIONS-SOLVED-BY-GRAMMAR.csv', 'QUESTIONS-SOLVED-BY-DISCOURSE.csv']\n",
    "    dicts = files_to_dict(data_dir, irl_filenames, fcg_filenames)\n",
    "    result = combine_irl_and_fcg(dicts[0], dicts[1], None)\n",
    "    plot_measures_stacked_bars(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########start hier --> werkt nog niet\n",
    "def plot_lines():\n",
    "    data_dir = \"data/\"\n",
    "    irl_filenames = ['irl-nodenames.csv','QUESTIONS-INTRODUCED-BY-DISCOURSE.csv', 'QUESTIONS-INTRODUCED-BY-ONTOLOGY.csv', 'QUESTIONS-INTRODUCED-BY-MENTAL-SIMULATION.csv' , 'QUESTIONS-SOLVED-BY-MENTAL-SIMULATION.csv', 'QUESTIONS-SOLVED-BY-ONTOLOGY.csv']\n",
    "    fcg_filenames = ['fcg-nodenames.csv','QUESTIONS-INTRODUCED-BY-GRAMMAR.csv', 'QUESTIONS-SOLVED-BY-GRAMMAR.csv', 'QUESTIONS-SOLVED-BY-DISCOURSE.csv']\n",
    "    dicts = files_to_dict(data_dir, irl_filenames, fcg_filenames)\n",
    "    result = combine_irl_and_fcg(dicts[0], dicts[1], None)\n",
    "    plot_measures_lines(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########start hier --> werkt nog niet\n",
    "def plot_remaining_questions():\n",
    "    data_dir = \"data/\"\n",
    "    irl_filenames = ['irl-nodenames.csv','QUESTIONS-INTRODUCED-BY-DISCOURSE.csv', 'QUESTIONS-INTRODUCED-BY-ONTOLOGY.csv', 'QUESTIONS-INTRODUCED-BY-MENTAL-SIMULATION.csv' , 'QUESTIONS-SOLVED-BY-MENTAL-SIMULATION.csv', 'QUESTIONS-SOLVED-BY-ONTOLOGY.csv']\n",
    "    fcg_filenames = ['fcg-nodenames.csv','QUESTIONS-INTRODUCED-BY-GRAMMAR.csv', 'QUESTIONS-SOLVED-BY-GRAMMAR.csv', 'QUESTIONS-SOLVED-BY-DISCOURSE.csv']\n",
    "    dicts = files_to_dict(data_dir, irl_filenames, fcg_filenames)\n",
    "    result = combine_irl_and_fcg(dicts[0], dicts[1], None)\n",
    "    plot_measures_remaining_questions(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_to_dict(data_dir, irl_filenames, fcg_filenames):\n",
    "    d = {}\n",
    "    d_irl = {}\n",
    "    for file_name in os.listdir(data_dir): \n",
    "        f = os.path.join(data_dir, file_name)\n",
    "        file = open(f)\n",
    "        csv_reader = csv.reader(file, delimiter=' ')\n",
    "        lst = []\n",
    "        irl_lst = []\n",
    "        if file_name in fcg_filenames : \n",
    "            for row in csv_reader: \n",
    "                lst.append(row) \n",
    "                d[file_name] = lst\n",
    "        elif file_name in irl_filenames: \n",
    "            for row in csv_reader: \n",
    "                irl_lst.append(row) \n",
    "                d_irl[file_name] = irl_lst\n",
    "    return d, d_irl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_irl_and_fcg(d, d_irl, flatten):\n",
    "    # now combine fcg and irl \n",
    "\n",
    "    fcg_nodenames = d['fcg-nodenames.csv']\n",
    "    irl_nodenames = d_irl['irl-nodenames.csv']\n",
    "\n",
    "    fcg_introduced_vars = d['QUESTIONS-INTRODUCED-BY-GRAMMAR.csv']\n",
    "    fcg_bound_vars = d['QUESTIONS-SOLVED-BY-GRAMMAR.csv']\n",
    "    fcg_bound_aes = d['QUESTIONS-SOLVED-BY-DISCOURSE.csv']\n",
    "\n",
    "    irl_bound_vars = d_irl['QUESTIONS-SOLVED-BY-MENTAL-SIMULATION.csv']\n",
    "    irl_bound_slots = d_irl['QUESTIONS-SOLVED-BY-ONTOLOGY.csv']\n",
    "\n",
    "    irl_introduced_vars = d_irl['QUESTIONS-INTRODUCED-BY-MENTAL-SIMULATION.csv']\n",
    "    irl_introduced_aes = d_irl['QUESTIONS-INTRODUCED-BY-DISCOURSE.csv']\n",
    "    irl_introduced_slots = d_irl['QUESTIONS-INTRODUCED-BY-ONTOLOGY.csv']\n",
    "\n",
    "    names = [irl_nodenames[0]]\n",
    "    introduced_by_grammar = [[0] * len(irl_nodenames[0])]\n",
    "    solved_by_grammar = [[0] * len(irl_nodenames[0])]\n",
    "    solved_by_discourse = [[0] * len(irl_nodenames[0])]\n",
    "    \n",
    "    irl_nodenames = irl_nodenames[1:]\n",
    "    \n",
    "    introduced_by_simulation = [irl_introduced_vars[0]]\n",
    "    irl_introduced_vars = irl_introduced_vars[1:]\n",
    "    \n",
    "    introduced_by_ontology = [irl_introduced_slots[0]]\n",
    "    irl_introduced_slots = irl_introduced_slots[1:]\n",
    "    \n",
    "    introduced_by_discourse = [irl_introduced_aes[0]]\n",
    "    irl_introduced_aes = irl_introduced_aes[1:]\n",
    "    \n",
    "    solved_by_simulation = [irl_bound_vars[0]]\n",
    "    irl_bound_vars = irl_bound_vars[1:]\n",
    "    \n",
    "    solved_by_ontology = [irl_bound_slots[0]]\n",
    "    irl_bound_slots = irl_bound_slots[1:]\n",
    "    \n",
    "    #make list of fcg + irl nodenames\n",
    "    for fcg_names,irl_names in zip(fcg_nodenames, irl_nodenames): \n",
    "        names.append(fcg_names)\n",
    "        names.append(irl_names)\n",
    "     \n",
    "    for intro_vars,bound_vars, bound_aes, irl_names in zip(fcg_introduced_vars, fcg_bound_vars, fcg_bound_aes, irl_nodenames): \n",
    "        introduced_by_grammar.append(intro_vars)\n",
    "        solved_by_grammar.append(bound_vars)\n",
    "        solved_by_discourse.append(bound_aes)\n",
    "        \n",
    "        irl_nodes = [0] * len(irl_names)\n",
    "        \n",
    "        introduced_by_grammar.append(irl_nodes)\n",
    "        solved_by_grammar.append(irl_nodes)\n",
    "        solved_by_discourse.append(irl_nodes)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    for fcg_names, bound_vars, bound_slots, intro_vars, intro_aes, intro_slots in zip(fcg_nodenames, irl_bound_vars, irl_bound_slots, irl_introduced_vars, irl_introduced_aes, irl_introduced_slots):\n",
    "        solved_by_simulation.append(bound_vars)\n",
    "        solved_by_ontology.append(bound_slots)\n",
    "        introduced_by_simulation.append(intro_vars)\n",
    "        introduced_by_discourse.append(intro_aes)\n",
    "        introduced_by_ontology.append(intro_slots)\n",
    "        \n",
    "        fcg_nodes = [0] * len(fcg_names)\n",
    "        \n",
    "        solved_by_simulation.append(fcg_nodes)\n",
    "        solved_by_ontology.append(fcg_nodes)\n",
    "        introduced_by_simulation.append(fcg_nodes)\n",
    "        introduced_by_discourse.append(fcg_nodes)\n",
    "        introduced_by_ontology.append(fcg_nodes)\n",
    "        \n",
    "    final_d = {}    \n",
    "    final_d['nodenames'] = names\n",
    "    final_d['introduced_by_grammar'] = introduced_by_grammar\n",
    "    final_d['introduced_by_simulation'] = introduced_by_simulation\n",
    "    final_d['introduced_by_discourse'] = introduced_by_discourse\n",
    "    final_d['introduced_by_ontology'] = introduced_by_ontology\n",
    "    final_d['solved_by_grammar'] = solved_by_grammar\n",
    "    final_d['solved_by_simulation'] = solved_by_simulation\n",
    "    final_d['solved_by_discourse'] = solved_by_discourse\n",
    "    final_d['solved_by_ontology'] = solved_by_ontology\n",
    "    #print(final_d)\n",
    "    flattened_dictionary = {}\n",
    "\n",
    "    for key in final_d.keys():\n",
    "        regular_list = final_d[key]\n",
    "        if key != \"nodenames\": \n",
    "            lst = [int(item) for sublist in regular_list for item in sublist]\n",
    "        else: \n",
    "            lst = [item for sublist in regular_list for item in sublist]\n",
    "        flattened_dictionary[key] = lst \n",
    "        #print(key, \": \", len(lst))\n",
    "\n",
    "    if flatten: \n",
    "        return flattened_dictionary\n",
    "    else: \n",
    "        return final_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### nieuwe plots\n",
    "def plot_measures_pie(dictionary):\n",
    "\n",
    "    node_names = dictionary['nodenames']\n",
    "    \n",
    "    introduced_by_grammar = dictionary['introduced_by_grammar']\n",
    "    introduced_by_simulation = dictionary['introduced_by_simulation']\n",
    "    introduced_by_ontology = dictionary['introduced_by_ontology']\n",
    "    introduced_by_discourse = dictionary['introduced_by_discourse']\n",
    "    \n",
    "    solved_by_grammar = dictionary['solved_by_grammar']\n",
    "    solved_by_simulation = dictionary['solved_by_simulation']\n",
    "    solved_by_ontology = dictionary['solved_by_ontology']\n",
    "    solved_by_discourse = dictionary['solved_by_discourse']\n",
    " \n",
    "    introduced_vars = []\n",
    "    \n",
    "    for q_grammar, q_simulation, q_discourse, q_ontology in zip(introduced_by_grammar, introduced_by_simulation, introduced_by_discourse, introduced_by_ontology):\n",
    "        introduced_vars.append(int(q_grammar) + int(q_simulation) + int(q_discourse) + int(q_ontology))\n",
    "\n",
    "    lst = []\n",
    "    for i in range(0,len(introduced_vars)):\n",
    "        lst.append(i)\n",
    "    \n",
    "    node_ids = []\n",
    "    for i,node in enumerate(node_names): \n",
    "        if node == \"initial\": \n",
    "            node_ids.append(i)\n",
    "    \n",
    "    node_ids.append(len(node_names))\n",
    "    \n",
    "    node_ids = [11, 19, 28, 37, 45, 53, 61, 74, 87, 96, 100, 111, 117, 131, 136]\n",
    "   # [0, 2, 9, 12, 18, 20, 27, 29, 36, 38, 44, 46, 52, 54, 60, 62, 71, 75, 84, 88, 94, 97, 99, 101, 108, 112, 115, 118, 130, 132, 135, 137]\n",
    "    #for x in range(0, len(introduced_vars)):\n",
    "    explode = [0, 0, 0, 0, 0.1]\n",
    "    for x in node_ids:\n",
    "        total = sum(introduced_vars[:x])\n",
    "        print(sum(solved_by_grammar[:x]))\n",
    "        print(sum(solved_by_simulation[:x]))\n",
    "        print(sum(solved_by_ontology[:x]))\n",
    "        print(sum(solved_by_discourse[:x]))\n",
    "        bound_vars = {'Answers from language': sum(solved_by_grammar[:x]), \n",
    "                     'Answers from mental simulation': sum(solved_by_simulation[:x]), \n",
    "                     'Answers from ontology' : sum(solved_by_ontology[:x]), \n",
    "                     'Answers from discourse model': sum(solved_by_discourse[:x]), \n",
    "                     'Remaining questions': sum(introduced_vars[:x]) - sum(solved_by_grammar[:x]) - sum(solved_by_simulation[:x]) - sum(solved_by_ontology[:x]) - sum(solved_by_discourse[:x])}\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(18.5, 10.5)\n",
    "        ax.pie(bound_vars.values(), \n",
    "                 labels=bound_vars.keys(),explode = explode, autopct='%1.1f%%')\n",
    "        ax.axis('equal')\n",
    "\n",
    "        plt.show()\n",
    "       # plt.savefig('measures-for-understanding-aes-questions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_pies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### nieuwe plots\n",
    "def plot_measures_stackplot(dictionary):\n",
    "    \n",
    "    node_names = dictionary['nodenames']\n",
    "    \n",
    "    introduced_by_grammar = dictionary['introduced_by_grammar']\n",
    "    introduced_by_simulation = dictionary['introduced_by_simulation']\n",
    "    introduced_by_ontology = dictionary['introduced_by_ontology']\n",
    "    introduced_by_discourse = dictionary['introduced_by_discourse']\n",
    "    \n",
    "    intro_by_grammar = []\n",
    "    intro_by_simulation = []\n",
    "    intro_by_ontology = []\n",
    "    intro_by_discourse = []\n",
    "    \n",
    "    for g, s, o, d in zip(introduced_by_grammar, introduced_by_simulation, introduced_by_ontology, introduced_by_discourse): \n",
    "        g = [int(x) for x in g]\n",
    "        s = [int(x) for x in s]\n",
    "        o = [int(x) for x in o]\n",
    "        d = [int(x) for x in d]\n",
    "        intro_by_grammar.append(sum(g))\n",
    "        intro_by_simulation.append(sum(s))\n",
    "        intro_by_ontology.append(sum(o))\n",
    "        intro_by_discourse.append(sum(d))\n",
    "    \n",
    "    solved_by_grammar = dictionary['solved_by_grammar']\n",
    "    solved_by_simulation = dictionary['solved_by_simulation']\n",
    "    solved_by_ontology = dictionary['solved_by_ontology']\n",
    "    solved_by_discourse = dictionary['solved_by_discourse']\n",
    "    \n",
    "    sol_by_grammar = []\n",
    "    sol_by_simulation = []\n",
    "    sol_by_ontology = []\n",
    "    sol_by_discourse = []\n",
    "    \n",
    "    for g, s, o, d in zip(solved_by_grammar, solved_by_simulation, solved_by_ontology, solved_by_discourse):\n",
    "        g = [int(x) for x in g]\n",
    "        \n",
    "        s = [int(x) for x in s]\n",
    "        print(s)\n",
    "        o = [int(x) for x in o]\n",
    "        d = [int(x) for x in d]\n",
    "        \n",
    "        sol_by_grammar.append(sum(g))\n",
    "        sol_by_simulation.append(sum(s))\n",
    "        sol_by_ontology.append(sum(o))\n",
    "        sol_by_discourse.append(sum(d))\n",
    " \n",
    "    sol_by_grammar = cumSum(sol_by_grammar)\n",
    "    sol_by_simulation = cumSum(sol_by_simulation)\n",
    "    sol_by_ontology = cumSum(sol_by_ontology)\n",
    "    sol_by_discourse = cumSum(sol_by_discourse)\n",
    " \n",
    "    introduced_vars = []\n",
    "    \n",
    "    for q_grammar, q_simulation, q_discourse, q_ontology in zip(intro_by_grammar, intro_by_simulation, intro_by_discourse, intro_by_ontology):\n",
    "        introduced_vars.append(int(q_grammar) + int(q_simulation) + int(q_discourse) + int(q_ontology))\n",
    "\n",
    "    introduced_vars = cumSum(introduced_vars)\n",
    "    lst = []\n",
    "    for i in range(0,len(introduced_vars)):\n",
    "        lst.append(i)\n",
    "    print(introduced_vars)\n",
    "    \n",
    "    bound_vars = {'Answers from language': sol_by_grammar, \n",
    "                 'Answers from mental simulation': sol_by_simulation, \n",
    "                 'Answers from ontology' : sol_by_ontology, \n",
    "                 'Answers from discourse model': sol_by_discourse}\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "    ax.stackplot(lst, bound_vars.values(),\n",
    "             labels=bound_vars.keys(), alpha=0.8)\n",
    "\n",
    "    ax.plot(introduced_vars, label='Total number of questions',color=\"black\", linewidth=1.5)\n",
    "    \n",
    "    plt.xticks([])\n",
    "   # plt.hlines(y=range(0, 350, 50), xmin= 0, xmax=len(introduced_vars) - 1, linestyles='dashdot', color='gray')\n",
    "\n",
    "    ax.set_ylabel('Number of answers')\n",
    "    ax.set_xlabel('Steps in recipe execution')\n",
    "   # ax.set_title('Understanding Process')\n",
    "    ax.legend(prop={\"size\":20})\n",
    "   #  \n",
    "   # ax.title.set_fontsize(20)\n",
    "    ax.yaxis.label.set_fontsize(20)\n",
    "    ax.xaxis.label.set_fontsize(20)\n",
    "    plt.yticks(fontsize=15)\n",
    "    #plt.show()\n",
    "    plt.savefig('stackplot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### nieuwe plots\n",
    "def plot_measures_stackplot_questions(dictionary):\n",
    "    \n",
    "    node_names = dictionary['nodenames']\n",
    "    \n",
    "    introduced_by_grammar = dictionary['introduced_by_grammar']\n",
    "    introduced_by_simulation = dictionary['introduced_by_simulation']\n",
    "    introduced_by_ontology = dictionary['introduced_by_ontology']\n",
    "    introduced_by_discourse = dictionary['introduced_by_discourse']\n",
    "    \n",
    "    intro_by_grammar = []\n",
    "    intro_by_simulation = []\n",
    "    intro_by_ontology = []\n",
    "    intro_by_discourse = []\n",
    "    \n",
    "    for g, s, o, d in zip(introduced_by_grammar, introduced_by_simulation, introduced_by_ontology, introduced_by_discourse): \n",
    "        g = [int(x) for x in g]\n",
    "        s = [int(x) for x in s]\n",
    "        o = [int(x) for x in o]\n",
    "        d = [int(x) for x in d]\n",
    "        intro_by_grammar.append(sum(g))\n",
    "        intro_by_simulation.append(sum(s))\n",
    "        intro_by_ontology.append(sum(o))\n",
    "        intro_by_discourse.append(sum(d))\n",
    "    \n",
    "    int_by_grammar = cumSum(intro_by_grammar)\n",
    "    int_by_simulation = cumSum(intro_by_simulation)\n",
    "    int_by_ontology = cumSum(intro_by_ontology)\n",
    "    int_by_discourse = cumSum(intro_by_discourse)\n",
    "    \n",
    "    solved_by_grammar = dictionary['solved_by_grammar']\n",
    "    solved_by_simulation = dictionary['solved_by_simulation']\n",
    "    solved_by_ontology = dictionary['solved_by_ontology']\n",
    "    solved_by_discourse = dictionary['solved_by_discourse']\n",
    "    \n",
    "    sol_by_grammar = []\n",
    "    sol_by_simulation = []\n",
    "    sol_by_ontology = []\n",
    "    sol_by_discourse = []\n",
    "    \n",
    "    for g, s, o, d in zip(solved_by_grammar, solved_by_simulation, solved_by_ontology, solved_by_discourse):\n",
    "        g = [int(x) for x in g]\n",
    "        \n",
    "        s = [int(x) for x in s]\n",
    "        print(s)\n",
    "        o = [int(x) for x in o]\n",
    "        d = [int(x) for x in d]\n",
    "        \n",
    "        sol_by_grammar.append(sum(g))\n",
    "        sol_by_simulation.append(sum(s))\n",
    "        sol_by_ontology.append(sum(o))\n",
    "        sol_by_discourse.append(sum(d))\n",
    " \n",
    "    sol_by_grammar = cumSum(sol_by_grammar)\n",
    "    sol_by_simulation = cumSum(sol_by_simulation)\n",
    "    sol_by_ontology = cumSum(sol_by_ontology)\n",
    "    sol_by_discourse = cumSum(sol_by_discourse)\n",
    " \n",
    "    introduced_vars = []\n",
    "    \n",
    "    for q_grammar, q_simulation, q_discourse, q_ontology in zip(intro_by_grammar, intro_by_simulation, intro_by_discourse, intro_by_ontology):\n",
    "        introduced_vars.append(int(q_grammar) + int(q_simulation) + int(q_discourse) + int(q_ontology))\n",
    "\n",
    "    introduced_vars = cumSum(introduced_vars)\n",
    "    lst = []\n",
    "    for i in range(0,len(introduced_vars)):\n",
    "        lst.append(i)\n",
    "    print(introduced_vars)\n",
    "    \n",
    "    bound_vars = {'Questions from language': int_by_grammar, \n",
    "                 'Questions from mental simulation': int_by_simulation, \n",
    "                 'Questions from ontology' : int_by_ontology, \n",
    "                 'Questions from discourse model': int_by_discourse}\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "    ax.stackplot(lst, bound_vars.values(),\n",
    "             labels=bound_vars.keys(), alpha=0.8)\n",
    "\n",
    "    #ax.plot(introduced_vars, label='Total number of questions',color=\"black\", linewidth=1.5)\n",
    "    \n",
    "    plt.xticks([])\n",
    "   # plt.hlines(y=range(0, 350, 50), xmin= 0, xmax=len(introduced_vars) - 1, linestyles='dashdot', color='gray')\n",
    "\n",
    "    ax.set_ylabel('Number of questions')\n",
    "    ax.set_xlabel('Steps in recipe execution')\n",
    "   # ax.set_title('Understanding Process')\n",
    "    ax.legend(prop={\"size\":20})\n",
    "   #  \n",
    "   # ax.title.set_fontsize(20)\n",
    "    ax.yaxis.label.set_fontsize(20)\n",
    "    ax.xaxis.label.set_fontsize(20)\n",
    "    plt.yticks(fontsize=15)\n",
    "    #plt.show()\n",
    "    plt.savefig('stackplot_introduced.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stackplot_introduced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_stackplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### nieuwe plots\n",
    "def plot_measures_stacked_bars(dictionary):\n",
    "    \n",
    "    node_names = dictionary['nodenames']\n",
    "    \n",
    "    introduced_by_grammar = dictionary['introduced_by_grammar']\n",
    "    introduced_by_simulation = dictionary['introduced_by_simulation']\n",
    "    introduced_by_ontology = dictionary['introduced_by_ontology']\n",
    "    introduced_by_discourse = dictionary['introduced_by_discourse']\n",
    "    \n",
    "    intro_by_grammar = []\n",
    "    intro_by_simulation = []\n",
    "    intro_by_ontology = []\n",
    "    intro_by_discourse = []\n",
    "    \n",
    "    for g, s, o, d in zip(introduced_by_grammar, introduced_by_simulation, introduced_by_ontology, introduced_by_discourse): \n",
    "        g = [int(x) for x in g]\n",
    "        s = [int(x) for x in s]\n",
    "        o = [int(x) for x in o]\n",
    "        d = [int(x) for x in d]\n",
    "        intro_by_grammar.append(sum(g))\n",
    "        intro_by_simulation.append(sum(s))\n",
    "        intro_by_ontology.append(sum(o))\n",
    "        intro_by_discourse.append(sum(d))\n",
    "    \n",
    "    solved_by_grammar = dictionary['solved_by_grammar']\n",
    "    solved_by_simulation = dictionary['solved_by_simulation']\n",
    "    solved_by_ontology = dictionary['solved_by_ontology']\n",
    "    solved_by_discourse = dictionary['solved_by_discourse']\n",
    "    \n",
    "    sol_by_grammar = []\n",
    "    sol_by_simulation = []\n",
    "    sol_by_ontology = []\n",
    "    sol_by_discourse = []\n",
    "    \n",
    "    for g, s, o, d in zip(solved_by_grammar, solved_by_simulation, solved_by_ontology, solved_by_discourse):\n",
    "        g = [int(x) for x in g]\n",
    "        \n",
    "        s = [int(x) for x in s]\n",
    "        print(s)\n",
    "        o = [int(x) for x in o]\n",
    "        d = [int(x) for x in d]\n",
    "        \n",
    "        sol_by_grammar.append(sum(g))\n",
    "        sol_by_simulation.append(sum(s))\n",
    "        sol_by_ontology.append(sum(o))\n",
    "        sol_by_discourse.append(sum(d))\n",
    " \n",
    "    sol_by_grammar = cumSum(sol_by_grammar)\n",
    "    sol_by_simulation = cumSum(sol_by_simulation)\n",
    "    sol_by_ontology = cumSum(sol_by_ontology)\n",
    "    sol_by_discourse = cumSum(sol_by_discourse)\n",
    "    \n",
    "    introduced_vars = []\n",
    "    solved_vars = []\n",
    "    \n",
    "    for q_grammar, q_simulation, q_discourse, q_ontology in zip(intro_by_grammar, intro_by_simulation, intro_by_discourse, intro_by_ontology):\n",
    "        introduced_vars.append(q_grammar + q_simulation + q_discourse + q_ontology)\n",
    "\n",
    "    for q_grammar, q_simulation, q_discourse, q_ontology in zip(sol_by_grammar, sol_by_simulation, sol_by_discourse, sol_by_ontology):\n",
    "        solved_vars.append(q_grammar + q_simulation + q_discourse + q_ontology)\n",
    "        \n",
    "    introduced_vars = cumSum(introduced_vars)\n",
    "    #solved_vars = cumSum(solved_vars)\n",
    "    \n",
    "    \n",
    "    lst = []\n",
    "    for i in range(0,len(introduced_vars)):\n",
    "        lst.append(i)\n",
    "    \n",
    "    remaining_questions = []\n",
    "    for iv, sv in zip(introduced_vars, solved_vars): \n",
    "        remaining_questions.append(iv - sv)\n",
    "    print(remaining_questions)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(lst, sol_by_grammar, label='Answers from language', color=\"#1f77b4\")\n",
    "    ax.bar(lst, sol_by_simulation, bottom=sol_by_grammar , label='Answers from mental simulation', color=\"#2ca02c\")\n",
    "    ax.bar(lst, sol_by_ontology, bottom=[sum(x) for x in zip(sol_by_grammar, sol_by_simulation)] , label='Answers from ontology', color=\"#ff7f0e\")\n",
    "    ax.bar(lst, sol_by_discourse, bottom=[sum(x) for x in zip(sol_by_grammar, sol_by_simulation,sol_by_ontology)], label='Answers from discourse model', color=\"#d62728\")\n",
    "    ax.bar(lst, remaining_questions, bottom=[sum(x) for x in zip(sol_by_grammar, sol_by_simulation,sol_by_ontology, sol_by_discourse)], label='Remaining questions', color=\"#800080\")\n",
    "   \n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "    #ax.stackplot(lst, bound_vars.values(),\n",
    "    #         labels=bound_vars.keys(), alpha=0.8)\n",
    "\n",
    "    #ax.plot(introduced_vars, label='Total number of questions',color=\"black\", linewidth=1.0)\n",
    "    \n",
    "    plt.xticks([])\n",
    "\n",
    "    ax.set_ylabel('Number of questions/answers')\n",
    "    ax.set_xlabel('Steps in recipe execution')\n",
    "   # ax.set_title('Understanding Process')\n",
    "    ax.legend(prop={\"size\":15})\n",
    "   #  \n",
    "   # ax.title.set_fontsize(20)\n",
    "   # ax.yaxis.label.set_fontsize(15)\n",
    "   # ax.xaxis.label.set_fontsize(15)\n",
    "\n",
    "    plt.show()\n",
    "   # plt.savefig('measures-for-understanding-aes-questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stacked_bars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### nieuwe plots\n",
    "def plot_measures_lines(dictionary):\n",
    "    \n",
    "    node_names = dictionary['nodenames']\n",
    "    \n",
    "    introduced_by_grammar = dictionary['introduced_by_grammar']\n",
    "    introduced_by_simulation = dictionary['introduced_by_simulation']\n",
    "    introduced_by_ontology = dictionary['introduced_by_ontology']\n",
    "    introduced_by_discourse = dictionary['introduced_by_discourse']\n",
    "    \n",
    "    intro_by_grammar = []\n",
    "    intro_by_simulation = []\n",
    "    intro_by_ontology = []\n",
    "    intro_by_discourse = []\n",
    "    \n",
    "    for g, s, o, d in zip(introduced_by_grammar, introduced_by_simulation, introduced_by_ontology, introduced_by_discourse): \n",
    "        g = [int(x) for x in g]\n",
    "        s = [int(x) for x in s]\n",
    "        o = [int(x) for x in o]\n",
    "        d = [int(x) for x in d]\n",
    "        intro_by_grammar.append(sum(g))\n",
    "        intro_by_simulation.append(sum(s))\n",
    "        intro_by_ontology.append(sum(o))\n",
    "        intro_by_discourse.append(sum(d))\n",
    "    \n",
    "    solved_by_grammar = dictionary['solved_by_grammar']\n",
    "    solved_by_simulation = dictionary['solved_by_simulation']\n",
    "    solved_by_ontology = dictionary['solved_by_ontology']\n",
    "    solved_by_discourse = dictionary['solved_by_discourse']\n",
    "    \n",
    "    sol_by_grammar = []\n",
    "    sol_by_simulation = []\n",
    "    sol_by_ontology = []\n",
    "    sol_by_discourse = []\n",
    "    \n",
    "    for g, s, o, d in zip(solved_by_grammar, solved_by_simulation, solved_by_ontology, solved_by_discourse):\n",
    "        g = [int(x) for x in g]\n",
    "        s = [int(x) for x in s]\n",
    "        o = [int(x) for x in o]\n",
    "        d = [int(x) for x in d]\n",
    "        \n",
    "        sol_by_grammar.append(sum(g))\n",
    "        sol_by_simulation.append(sum(s))\n",
    "        sol_by_ontology.append(sum(o))\n",
    "        sol_by_discourse.append(sum(d))\n",
    " \n",
    "   # sol_by_grammar = cumSum(sol_by_grammar)\n",
    "   # sol_by_simulation = cumSum(sol_by_simulation)\n",
    "   # sol_by_ontology = cumSum(sol_by_ontology)\n",
    "   # sol_by_discourse = cumSum(sol_by_discourse)\n",
    "    \n",
    "    introduced_vars = []\n",
    "    solved_vars = []\n",
    "    \n",
    "    for q_grammar, q_simulation, q_discourse, q_ontology in zip(intro_by_grammar, intro_by_simulation, intro_by_discourse, intro_by_ontology):\n",
    "        introduced_vars.append(q_grammar + q_simulation + q_discourse + q_ontology)\n",
    "    \n",
    "    for q_grammar, q_simulation, q_discourse, q_ontology in zip(sol_by_grammar, sol_by_simulation, sol_by_discourse, sol_by_ontology):\n",
    "        solved_vars.append(q_grammar + q_simulation + q_discourse + q_ontology)\n",
    "\n",
    "    introduced_vars = cumSum(introduced_vars)\n",
    "    solved_vars = cumSum(solved_vars)\n",
    "    \n",
    "\n",
    "    lst = []\n",
    "    for i in range(0,len(introduced_vars)):\n",
    "        lst.append(i)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "   \n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "    print(solved_vars)\n",
    "    print(introduced_vars)\n",
    "    ax.plot(introduced_vars, label='Total number of questions',color=\"black\", linewidth=1.0)\n",
    "    ax.plot(solved_vars, label='Total number of answers',color=\"red\", linewidth=1.0)\n",
    "\n",
    "    plt.xticks([])\n",
    "\n",
    "    ax.set_ylabel('Number of questions/answers')\n",
    "    ax.set_xlabel('Steps in recipe execution')\n",
    "   # ax.set_title('Understanding Process')\n",
    "    ax.legend(prop={\"size\":20})\n",
    "   #  \n",
    "   # ax.title.set_fontsize(20)\n",
    "    ax.yaxis.label.set_fontsize(20)\n",
    "    ax.xaxis.label.set_fontsize(20)\n",
    "\n",
    "    plt.show()\n",
    "   # plt.savefig('measures-for-understanding-aes-questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### nieuwe plots\n",
    "def plot_measures_remaining_questions(dictionary):\n",
    "    \n",
    "    node_names = dictionary['nodenames']\n",
    "    \n",
    "    introduced_by_grammar = dictionary['introduced_by_grammar']\n",
    "    introduced_by_simulation = dictionary['introduced_by_simulation']\n",
    "    introduced_by_ontology = dictionary['introduced_by_ontology']\n",
    "    introduced_by_discourse = dictionary['introduced_by_discourse']\n",
    "    \n",
    "    intro_by_grammar = []\n",
    "    intro_by_simulation = []\n",
    "    intro_by_ontology = []\n",
    "    intro_by_discourse = []\n",
    "    \n",
    "    for g, s, o, d in zip(introduced_by_grammar, introduced_by_simulation, introduced_by_ontology, introduced_by_discourse): \n",
    "        g = [int(x) for x in g]\n",
    "        s = [int(x) for x in s]\n",
    "        o = [int(x) for x in o]\n",
    "        d = [int(x) for x in d]\n",
    "        intro_by_grammar.append(sum(g))\n",
    "        intro_by_simulation.append(sum(s))\n",
    "        intro_by_ontology.append(sum(o))\n",
    "        intro_by_discourse.append(sum(d))\n",
    "    \n",
    "    solved_by_grammar = dictionary['solved_by_grammar']\n",
    "    solved_by_simulation = dictionary['solved_by_simulation']\n",
    "    solved_by_ontology = dictionary['solved_by_ontology']\n",
    "    solved_by_discourse = dictionary['solved_by_discourse']\n",
    "    \n",
    "    sol_by_grammar = []\n",
    "    sol_by_simulation = []\n",
    "    sol_by_ontology = []\n",
    "    sol_by_discourse = []\n",
    "    \n",
    "    for g, s, o, d in zip(solved_by_grammar, solved_by_simulation, solved_by_ontology, solved_by_discourse):\n",
    "        g = [int(x) for x in g]\n",
    "        s = [int(x) for x in s]\n",
    "        o = [int(x) for x in o]\n",
    "        d = [int(x) for x in d]\n",
    "        \n",
    "        sol_by_grammar.append(sum(g))\n",
    "        sol_by_simulation.append(sum(s))\n",
    "        sol_by_ontology.append(sum(o))\n",
    "        sol_by_discourse.append(sum(d))\n",
    " \n",
    "   # sol_by_grammar = cumSum(sol_by_grammar)\n",
    "   # sol_by_simulation = cumSum(sol_by_simulation)\n",
    "   # sol_by_ontology = cumSum(sol_by_ontology)\n",
    "   # sol_by_discourse = cumSum(sol_by_discourse)\n",
    "    \n",
    "    introduced_vars = []\n",
    "    solved_vars = []\n",
    "    \n",
    "    for q_grammar, q_simulation, q_discourse, q_ontology in zip(intro_by_grammar, intro_by_simulation, intro_by_discourse, intro_by_ontology):\n",
    "        introduced_vars.append(q_grammar + q_simulation + q_discourse + q_ontology)\n",
    "    \n",
    "    for q_grammar, q_simulation, q_discourse, q_ontology in zip(sol_by_grammar, sol_by_simulation, sol_by_discourse, sol_by_ontology):\n",
    "        solved_vars.append(q_grammar + q_simulation + q_discourse + q_ontology)\n",
    "\n",
    "    introduced_vars = cumSum(introduced_vars)\n",
    "    solved_vars = cumSum(solved_vars)\n",
    "    remaining_questions = [0]\n",
    "    for iv, sv in zip(introduced_vars, solved_vars): \n",
    "        remaining_questions.append(iv - sv)\n",
    "        \n",
    "\n",
    "    lst = []\n",
    "    for i in range(0,len(introduced_vars)):\n",
    "        lst.append(i)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "   \n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "    #ax.stackplot(lst, bound_vars.values(),\n",
    "    #         labels=bound_vars.keys(), alpha=0.8)\n",
    "\n",
    "    print(solved_vars)\n",
    "    print(introduced_vars)\n",
    "    print(remaining_questions)\n",
    "    ax.plot(remaining_questions, label='Total number of remaining questions',color=\"red\", linewidth=1.0)\n",
    "    #ax.plot(solved_vars, label='Total number of answers',color=\"red\", linewidth=1.0)\n",
    "\n",
    "    plt.xticks([])\n",
    "\n",
    "    ax.set_ylabel('Number of questions')\n",
    "    ax.set_xlabel('Steps in recipe execution')\n",
    "   # ax.set_title('Understanding Process')\n",
    "    ax.legend(prop={\"size\":20})\n",
    "   #  \n",
    "   # ax.title.set_fontsize(20)\n",
    "    ax.yaxis.label.set_fontsize(20)\n",
    "    ax.xaxis.label.set_fontsize(20)\n",
    "    plt.yticks(fontsize=15)\n",
    "\n",
    "    #plt.show()\n",
    "    plt.savefig('remaining_questions.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_remaining_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [0]\n",
    "lst.append(3)\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_cumulative_list(cum_lst, greatest_el): \n",
    "    norm_cum_list = []\n",
    "    for el in cum_lst: \n",
    "        norm_cum_list.append(el/greatest_el)\n",
    "    return norm_cum_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_list = cumSum([0, 1, 2])\n",
    "norm_cumulative_list(cum_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total = 55 + 77 + 1 + 15\n",
    "bound_vars = {'Answers from language': 25, \n",
    "            'Answers from mental simulation': 32, \n",
    "            'Answers from ontology' : 69, \n",
    "            'Answers from discourse model': 14, \n",
    "            'Remaining questions': 55 + 77 + 1 + 15 - 25 - 32 - 69 - 14\n",
    "             }\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10.5, 13.5)\n",
    "\n",
    "explode = [0, 0, 0, 0, 0.1]\n",
    "\n",
    "ax.pie(bound_vars.values(), labels=None,autopct='%1.1f%%', explode=explode, textprops={'fontsize': 30})\n",
    "ax.axis('equal')\n",
    "plt.legend(labels=bound_vars.keys(),prop={'size': 20},loc='lower left')\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig(\"pie-after-instructions.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total = 118 + 367 + 1 + 23\n",
    "bound_vars = {'Answers from language': 33, \n",
    "            'Answers from mental simulation': 64, \n",
    "            'Answers from ontology' :  367, \n",
    "            'Answers from discourse model': 42, \n",
    "            'Remaining questions': 118 + 367 + 1 + 23 - 33 - 367 - 64 - 42\n",
    "             }\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10.5, 10.5)\n",
    "ax.pie(bound_vars.values(), labels=None,autopct='%1.1f%%',textprops={'fontsize': 30})\n",
    "ax.axis('equal')\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig(\"pie-after-mix.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total = 159 + 153 + 1 + 31\n",
    "bound_vars = {'Answers from language': 47, \n",
    "            'Answers from mental simulation': 120, \n",
    "            'Answers from ontology' : 115, \n",
    "            'Answers from discourse model': 62, \n",
    "            'Remaining questions': 159 + 153 + 1 + 31 - 47 - 120 - 115 - 62\n",
    "             }\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10.5, 13.5)\n",
    "explode = [0, 0, 0, 0, 0.1]\n",
    "ax.pie(bound_vars.values(), labels=None,autopct='%1.1f%%', explode = explode, textprops={'fontsize': 30})\n",
    "ax.axis('equal')\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig(\"pie-end.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total = 159 + 153 + 1 + 31\n",
    "bound_vars = {'Answers from language': 47, \n",
    "            'Answers from mental simulation': 121, \n",
    "            'Answers from ontology' : 114, \n",
    "            'Answers from discourse model': 62, \n",
    "            'Remaining questions': 159 + 153 + 1 + 31 - 47 - 121 - 114 - 62\n",
    "             }\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10.5, 10.5)\n",
    "ax.pie(bound_vars.values(), labels=None,autopct='%1.1f%%', textprops={'fontsize': 30})\n",
    "ax.axis('equal')\n",
    "\n",
    "#plt.show()\n",
    "plt.savefig(\"pie-end.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = ['initial', 'UNTIL-LIGHT-AND-FLUFFY-CXN', 'BEAT-CXN', 'SUGAR-CXN', 'THE-X-CXN', 'BUTTER-CXN', 'THE-X-CXN', 'VERB-X-AND-Y-TOGETHER-IMPERATIVE-TRANSITIVE-CXN', 'RESULTATIVE-CXN', 'initial' ,'TRANSFER-CONTENTS', 'TRANSFER-CONTENTS' ,'BEAT']\n",
    "\n",
    "q_grammar = [0, 0, 5, 0, 0, 0, 0, 16, 0, 0, 0, 0, 0]\n",
    "q_ontology = [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 11]\n",
    "q_discourse = [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
    "\n",
    "a_discourse = [0, 0, 0,0,  0, 2, 0, 2, 2, 0, 0, 0, 0]\n",
    "a_simulation = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 6, 4]\n",
    "a_ontology = [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 10]\n",
    "a_grammar = [0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0]\n",
    "\n",
    "print(len(q_grammar))\n",
    "print(len(a_discourse))\n",
    "\n",
    "qa_grammar = [0, 0, 0, 0, 5, 0,  0, 0,  0, 0,  0,0,  0, 0, 16, 4, 0, 0, 0,  0, 0, 0, 0,  0, 0, 0]\n",
    "\n",
    "x = np.arange(len(nodes))\n",
    "  # the width of the bars\n",
    "width = 0.35\n",
    "#fig, ax = plt.subplots()\n",
    "#rects1 = ax.bar(x - width/2, men_means, width, label='Men')\n",
    "#rects2 = ax.bar(x + width/2, women_means, width, label='Women')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x - 1, q_grammar, label='language', color=\"blue\")\n",
    "ax.bar(x + 1, a_discourse , label='discourse', color=\"red\")\n",
    "ax.bar(x - 1, q_ontology, label='ontology', bottom=q_grammar, color=\"green\")\n",
    "ax.bar(x + 1, a_ontology , label='Answers from mental simulation', color=\"green\")\n",
    "ax.bar(x - 1, q_discourse, label='Answers from language', color=\"red\")\n",
    "ax.bar(x + 1, a_grammar , label='Answers from mental simulation', color=\"blue\")\n",
    "\n",
    "#ax.bar(x + 1, a_simulation , label='Answers from mental simulation', color=\"#2ca02c\")\n",
    "#ax.bar(nodes, sol_by_ontology, bottom=[sum(x) for x in zip(sol_by_grammar, sol_by_simulation)] , label='Answers from ontology', color=\"#ff7f0e\")\n",
    "#ax.bar(nodes, sol_by_discourse, bottom=[sum(x) for x in zip(sol_by_grammar, sol_by_simulation,sol_by_ontology)], label='Answers from discourse model', color=\"#d62728\")\n",
    "#ax.bar(nodes, remaining_questions, bottom=[sum(x) for x in zip(sol_by_grammar, sol_by_simulation,sol_by_ontology, sol_by_discourse)], label='Remaining questions', color=\"#800080\")\n",
    "\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "#ax.bar_label(rects1, padding=3)\n",
    "#ax.bar_label(rects2, padding=3)\n",
    "\n",
    "#ax.stackplot(lst, bound_vars.values(),\n",
    "#         labels=bound_vars.keys(), alpha=0.8)\n",
    "\n",
    "#ax.plot(introduced_vars, label='Total number of questions',color=\"black\", linewidth=1.0)\n",
    "\n",
    "plt.xticks([])\n",
    "\n",
    "ax.set_ylabel('Number of questions/answers')\n",
    "ax.set_xlabel('Steps in recipe execution')\n",
    "# ax.set_title('Understanding Process')\n",
    "ax.legend(prop={\"size\":15})\n",
    "#  \n",
    "# ax.title.set_fontsize(20)\n",
    "# ax.yaxis.label.set_fontsize(15)\n",
    "# ax.xaxis.label.set_fontsize(15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    flattened_dictionary = {}\n",
    "\n",
    "\n",
    "    norm_introduced_vars = []\n",
    "    for el in introduced_vars: \n",
    "        norm_el = int(el) / int(introduced_vars[-1])\n",
    "        norm_introduced_vars.append(norm_el)\n",
    "    #print(norm_introduced_vars)\n",
    "\n",
    "    norm_bound_vars_fcg = []\n",
    "    for el in bound_vars_fcg: \n",
    "        norm_el = int(el) / int(introduced_vars[-1])\n",
    "        norm_bound_vars_fcg.append(norm_el)\n",
    "    #print(norm_bound_vars_fcg)\n",
    "\n",
    "    norm_bound_aes_fcg = []\n",
    "    for el in bound_aes_fcg: \n",
    "        norm_el = int(el) / int(introduced_vars[-1])\n",
    "        norm_bound_aes_fcg.append(norm_el)\n",
    "    #print(norm_bound_aes_fcg)\n",
    "\n",
    "    norm_bound_vars_irl = []\n",
    "    for el in bound_vars_irl: \n",
    "        norm_el = int(el) / int(introduced_vars[-1])\n",
    "        norm_bound_vars_irl.append(norm_el)\n",
    "    #print(norm_bound_vars_irl)\n",
    "    \n",
    "    norm_bound_slots_irl = []\n",
    "    for el in bound_vars_irl: \n",
    "        norm_el = int(el) / int(introduced_vars[-1])\n",
    "        norm_bound_slots_irl.append(norm_el)\n",
    "    #print(norm_bound_vars_irl)\n",
    "    \n",
    "   # fig, ax = plt.subplots()\n",
    "   # y_pos = range(len(node_names))\n",
    "   # plt.figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumSum(s):\n",
    "   sm=0\n",
    "   cum_list=[]\n",
    "   for i in s:\n",
    "      sm=sm+i\n",
    "      cum_list.append(sm)\n",
    "   return cum_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_irl_and_fcg_for_question_graph(d, d_irl):\n",
    "    # now combine fcg and irl \n",
    "\n",
    "    fcg_nodenames = d['fcg-nodenames.csv']\n",
    "    irl_nodenames = d_irl['irl-nodenames.csv']\n",
    "\n",
    "    fcg_introduced_vars = d['RECORD-VARIABLES-INTRODUCED-BY-GRAMMAR-MICRO.csv']\n",
    "\n",
    "    fcg_bound_vars = d['RECORD-VARIABLES-BOUND-BY-GRAMMAR-MICRO.csv']\n",
    "    fcg_bound_aes = d['RECORD-ACCESSIBLE-ENTITIES-BOUND-BY-GRAMMAR-MICRO.csv']\n",
    "\n",
    "    irl_bound_vars = d_irl['RECORD-ANCHORING-MICRO.csv']\n",
    "    irl_bound_slots = d_irl['RECORD-SET-SLOTS.csv']\n",
    "\n",
    "    irl_introduced_aes = d_irl['RECORD-QUESTIONS-IRL.csv']\n",
    "    irl_introduced_slots = d_irl['RECORD-SLOTS.csv']\n",
    "\n",
    "    names = [['initial', 'GET-KITCHEN']]\n",
    "    introduced_vars_fcg = [['0', '0']]\n",
    "    introduced_vars_slots = [['1', '0']]\n",
    "    introduced_vars_aes = [['0', '1']]\n",
    "    \n",
    "    bound_vars = [['1', '1']]\n",
    "    bound_vars_irl = []\n",
    "    bound_vars_fcg = []\n",
    "\n",
    "    #make list of fcg + irl nodenames\n",
    "    for fcg_names,irl_names in zip(fcg_nodenames, irl_nodenames): \n",
    "        names.append(fcg_names)   \n",
    "        names.append(irl_names)\n",
    "\n",
    "        \n",
    "    #make list of questions raised by fcg\n",
    "    for fcg_vars, irl_names in zip(fcg_introduced_vars, irl_nodenames): \n",
    "        introduced_vars_fcg.append(fcg_vars)\n",
    "        new_lst = list(range(0,len(irl_names))) #make list with everything set on 0\n",
    "        new_new_lst = []\n",
    "        for el in new_lst: \n",
    "            new_new_lst.append('0')\n",
    "        introduced_vars_fcg.append(new_new_lst)\n",
    "\n",
    "    for fcg_names, irl_intro_aes in zip(fcg_nodenames, irl_introduced_aes): \n",
    "        new_lst = list(range(0,len(fcg_names))) #make list with everything set on 0\n",
    "        new_new_lst = []\n",
    "        for el in new_lst: \n",
    "            new_new_lst.append('0')\n",
    "        introduced_vars_aes.append(new_new_lst)\n",
    "        introduced_vars_aes.append(irl_intro_aes)\n",
    "        \n",
    "    for fcg_names, irl_intro_aes in zip(fcg_nodenames, irl_introduced_slots): \n",
    "        new_lst = list(range(0,len(fcg_names))) #make list with everything set on 0\n",
    "        new_new_lst = []\n",
    "        for el in new_lst: \n",
    "            new_new_lst.append('0')\n",
    "        introduced_vars_slots.append(new_new_lst)\n",
    "        introduced_vars_slots.append(irl_intro_aes)\n",
    "    \n",
    "    print()\n",
    "    #combine lists of AES and slots (both introduced_irl)\n",
    "    for intro_aes, intro_slots in zip(irl_bound_vars, irl_bound_slots):\n",
    "        lst = []\n",
    "        for aes, slot in zip(intro_aes, intro_slots): \n",
    "            n = int(aes) + int(slot)\n",
    "            lst.append(n)\n",
    "        bound_vars_irl.append(lst)\n",
    "        #combine lists of AES and slots (both introduced_irl)\n",
    "        \n",
    "    for intro_aes, intro_slots in zip(fcg_bound_vars, fcg_bound_aes):\n",
    "        lst = []\n",
    "        for aes, slot in zip(intro_aes, intro_slots): \n",
    "            n = int(aes) + int(slot)\n",
    "            lst.append(n)\n",
    "        bound_vars_fcg.append(lst)\n",
    "        \n",
    "    \n",
    "    #make list of vars introduced by fcg and vars introduced by irl (AES) + slots\n",
    "    for fcg_bound_vars,irl_bound_vars in zip(bound_vars_fcg, bound_vars_irl): \n",
    "       \n",
    "        bound_vars.append(fcg_bound_vars)\n",
    "        bound_vars.append(irl_bound_vars)\n",
    "\n",
    "    \n",
    "\n",
    "    final_d = {}    \n",
    "    final_d['nodenames'] = names\n",
    "    final_d['bound_vars'] = bound_vars\n",
    "    final_d['introduced_vars_fcg'] = introduced_vars_fcg\n",
    "    final_d['introduced_vars_aes'] = introduced_vars_aes\n",
    "    final_d['introduced_vars_slots'] = introduced_vars_slots\n",
    "\n",
    "    return final_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### nieuwe plots\n",
    "def plot_measures_norm_new(final_d):\n",
    "\n",
    "    flattened_dictionary = {}\n",
    "\n",
    "    for key in final_d.keys():\n",
    "        regular_list = final_d[key]\n",
    "        lst = [item for sublist in regular_list for item in sublist]\n",
    "        flattened_dictionary[key] = lst \n",
    "\n",
    "    node_names = flattened_dictionary['nodenames']\n",
    "    introduced_vars = cumSum([int(item) for item in flattened_dictionary['introduced_vars']])\n",
    "    bound_vars_fcg = cumSum([int(item) for item in flattened_dictionary['bound_vars_fcg']])\n",
    "    bound_aes_fcg = cumSum([int(item) for item in flattened_dictionary['bound_aes_fcg']])\n",
    "    bound_vars_irl = cumSum([int(item) for item in flattened_dictionary['bound_vars_irl']])\n",
    "    bound_slots_irl = cumSum([int(item) for item in flattened_dictionary['bound_slots_irl']])\n",
    "\n",
    "    norm_introduced_vars = []\n",
    "    for el in introduced_vars: \n",
    "        norm_el = int(el) / int(introduced_vars[-1])\n",
    "        norm_introduced_vars.append(norm_el)\n",
    "    #print(norm_introduced_vars)\n",
    "\n",
    "    norm_bound_vars_fcg = []\n",
    "    for el in bound_vars_fcg: \n",
    "        norm_el = int(el) / int(introduced_vars[-1])\n",
    "        norm_bound_vars_fcg.append(norm_el)\n",
    "    #print(norm_bound_vars_fcg)\n",
    "\n",
    "    norm_bound_aes_fcg = []\n",
    "    for el in bound_aes_fcg: \n",
    "        norm_el = int(el) / int(introduced_vars[-1])\n",
    "        norm_bound_aes_fcg.append(norm_el)\n",
    "    #print(norm_bound_aes_fcg)\n",
    "\n",
    "    norm_bound_vars_irl = []\n",
    "    for el in bound_vars_irl: \n",
    "        norm_el = int(el) / int(introduced_vars[-1])\n",
    "        norm_bound_vars_irl.append(norm_el)\n",
    "    #print(norm_bound_vars_irl)\n",
    "    \n",
    "    norm_bound_slots_irl = []\n",
    "    for el in bound_vars_irl: \n",
    "        norm_el = int(el) / int(introduced_vars[-1])\n",
    "        norm_bound_slots_irl.append(norm_el)\n",
    "    #print(norm_bound_vars_irl)\n",
    "    \n",
    "   # fig, ax = plt.subplots()\n",
    "   # y_pos = range(len(node_names))\n",
    "   # plt.figure()\n",
    "\n",
    "    lst = []\n",
    "    for i in range(0,len(bound_vars_fcg)):\n",
    "        lst.append(i)\n",
    "\n",
    "   # ax.bar(lst, norm_bound_vars_fcg, label='Answers from language', color=\"#1f77b4\")\n",
    "   # ax.bar(lst, norm_bound_vars_irl, bottom=norm_bound_vars_fcg , label='Answers from mental simulation', color=\"#2ca02c\")\n",
    "   # ax.bar(lst, norm_bound_slots_irl, bottom=[sum(x) for x in zip(norm_bound_vars_fcg, norm_bound_vars_irl)] , label='Answers from ontology', color=\"#ff7f0e\")\n",
    "   # ax.bar(lst, norm_bound_aes_fcg, bottom=[sum(x) for x in zip(norm_bound_vars_fcg, norm_bound_vars_irl,norm_bound_slots_irl)], label='Answers from discourse model', color=\"#d62728\")\n",
    "\n",
    "    bound_vars = {'Answers from language': bound_vars_fcg, \n",
    "                 'Answers from mental simulation': bound_vars_irl, \n",
    "                 'Answers from ontology' : bound_slots_irl, \n",
    "                 'Answers from discourse model': bound_aes_fcg}\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "    ax.stackplot(lst, bound_vars.values(),\n",
    "             labels=bound_vars.keys(), alpha=0.8)\n",
    "\n",
    "    ax.plot(introduced_vars, label='Total number of questions',color=\"black\", linewidth=1.0)\n",
    "    \n",
    "    plt.xticks([])\n",
    "\n",
    "    ax.set_ylabel('Number of questions/answers')\n",
    "    ax.set_xlabel('Steps in recipe execution')\n",
    "   # ax.set_title('Understanding Process')\n",
    "    ax.legend(prop={\"size\":15})\n",
    "   #  \n",
    "   # ax.title.set_fontsize(20)\n",
    "   # ax.yaxis.label.set_fontsize(15)\n",
    "   # ax.xaxis.label.set_fontsize(15)\n",
    "\n",
    "    plt.show()\n",
    "   # plt.savefig('measures-for-understanding-aes-questions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### nieuwe plots\n",
    "def plot_measures_norm_pie(final_d):\n",
    "\n",
    "    flattened_dictionary = {}\n",
    "\n",
    "    for key in final_d.keys():\n",
    "        regular_list = final_d[key]\n",
    "        lst = [item for sublist in regular_list for item in sublist]\n",
    "        flattened_dictionary[key] = lst \n",
    "\n",
    "    node_names = flattened_dictionary['nodenames']\n",
    "    introduced_vars = cumSum([int(item) for item in flattened_dictionary['introduced_vars']])\n",
    "    bound_vars_fcg = cumSum([int(item) for item in flattened_dictionary['bound_vars_fcg']])\n",
    "    bound_aes_fcg = cumSum([int(item) for item in flattened_dictionary['bound_aes_fcg']])\n",
    "    bound_vars_irl = cumSum([int(item) for item in flattened_dictionary['bound_vars_irl']])\n",
    "    bound_slots_irl = cumSum([int(item) for item in flattened_dictionary['bound_slots_irl']])\n",
    "\n",
    "    norm_introduced_vars = []\n",
    "    for el in introduced_vars: \n",
    "        norm_el = int(el) / int(introduced_vars[-1])\n",
    "        norm_introduced_vars.append(norm_el)\n",
    "    #print(norm_introduced_vars)\n",
    "\n",
    "    norm_bound_vars_fcg = []\n",
    "    for el in bound_vars_fcg: \n",
    "        norm_el = int(el) / int(introduced_vars[-1])\n",
    "        norm_bound_vars_fcg.append(norm_el)\n",
    "    #print(norm_bound_vars_fcg)\n",
    "\n",
    "    norm_bound_aes_fcg = []\n",
    "    for el in bound_aes_fcg: \n",
    "        norm_el = int(el) / int(introduced_vars[-1])\n",
    "        norm_bound_aes_fcg.append(norm_el)\n",
    "    #print(norm_bound_aes_fcg)\n",
    "\n",
    "    norm_bound_vars_irl = []\n",
    "    for el in bound_vars_irl: \n",
    "        norm_el = int(el) / int(introduced_vars[-1])\n",
    "        norm_bound_vars_irl.append(norm_el)\n",
    "    #print(norm_bound_vars_irl)\n",
    "    \n",
    "    norm_bound_slots_irl = []\n",
    "    for el in bound_vars_irl: \n",
    "        norm_el = int(el) / int(introduced_vars[-1])\n",
    "        norm_bound_slots_irl.append(norm_el)\n",
    "    #print(norm_bound_vars_irl)\n",
    "    \n",
    "   # fig, ax = plt.subplots()\n",
    "   # y_pos = range(len(node_names))\n",
    "    #plt.xticks(y_pos, node_names, rotation=90)\n",
    "   # plt.figure()\n",
    "\n",
    "    lst = []\n",
    "    for i in range(0,len(bound_vars_fcg)):\n",
    "        lst.append(i)\n",
    "\n",
    "   # ax.bar(lst, norm_bound_vars_fcg, label='Answers from language', color=\"#1f77b4\")\n",
    "   # ax.bar(lst, norm_bound_vars_irl, bottom=norm_bound_vars_fcg , label='Answers from mental simulation', color=\"#2ca02c\")\n",
    "   # ax.bar(lst, norm_bound_slots_irl, bottom=[sum(x) for x in zip(norm_bound_vars_fcg, norm_bound_vars_irl)] , label='Answers from ontology', color=\"#ff7f0e\")\n",
    "   # ax.bar(lst, norm_bound_aes_fcg, bottom=[sum(x) for x in zip(norm_bound_vars_fcg, norm_bound_vars_irl,norm_bound_slots_irl)], label='Answers from discourse model', color=\"#d62728\")\n",
    "    print(len(norm_introduced_vars))\n",
    "    print(node_names)\n",
    "    print(norm_introduced_vars)\n",
    "    \n",
    "    for x in [61,74,87,96,111,117,131,len(norm_introduced_vars)-1]:\n",
    "        total = sum(norm_introduced_vars[:x])\n",
    "        bound_vars = {'Answers from language': sum(norm_bound_vars_fcg[:x]), \n",
    "                     'Answers from mental simulation': sum(norm_bound_vars_irl[:x]), \n",
    "                     'Answers from ontology' : sum(norm_bound_slots_irl[:x]), \n",
    "                     'Answers from discourse model': sum(norm_bound_aes_fcg[:x]),\n",
    "                     'Remaining questions': total - sum(norm_bound_vars_fcg[:x]) - sum(norm_bound_vars_irl[:x]) - sum(norm_bound_slots_irl[:x]) - sum(norm_bound_aes_fcg[:x])}\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(18.5, 10.5)\n",
    "        explode = (0, 0, 0, 0, 0.1) \n",
    "        ax.pie(bound_vars.values(), explode=explode,\n",
    "                 labels=bound_vars.keys(),autopct='%1.1f%%')\n",
    "        ax.axis('equal')\n",
    "        #ax.plot(norm_introduced_vars, label='Total number of questions',color=\"black\", linewidth=1.0)\n",
    "\n",
    "        #ax.set_ylabel('Number of questions/answers')\n",
    "        #ax.set_xlabel('Steps in recipe execution')\n",
    "       # ax.set_title('Understanding Process')\n",
    "       # ax.legend(prop={\"size\":15})\n",
    "       #  \n",
    "       # ax.title.set_fontsize(20)\n",
    "       # ax.yaxis.label.set_fontsize(15)\n",
    "       # ax.xaxis.label.set_fontsize(15)\n",
    "\n",
    "        plt.show()\n",
    "       # plt.savefig('measures-for-understanding-aes-questions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_whole_norm_pie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### nieuwe plots\n",
    "def plot_measures_norm_pie(final_d):\n",
    "\n",
    "    flattened_dictionary = {}\n",
    "\n",
    "    for key in final_d.keys():\n",
    "        regular_list = final_d[key]\n",
    "        lst = [item for sublist in regular_list for item in sublist]\n",
    "        flattened_dictionary[key] = lst \n",
    "\n",
    "    node_names = flattened_dictionary['nodenames']\n",
    "    introduced_vars = cumSum([int(item) for item in flattened_dictionary['introduced_vars']])\n",
    "    bound_vars_fcg = cumSum([int(item) for item in flattened_dictionary['bound_vars_fcg']])\n",
    "    bound_aes_fcg = cumSum([int(item) for item in flattened_dictionary['bound_aes_fcg']])\n",
    "    bound_vars_irl = cumSum([int(item) for item in flattened_dictionary['bound_vars_irl']])\n",
    "    bound_slots_irl = cumSum([int(item) for item in flattened_dictionary['bound_slots_irl']])\n",
    "\n",
    "   # norm_introduced_vars = []\n",
    "   # for el in introduced_vars: \n",
    "   #     norm_el = int(el) / int(introduced_vars[-1])\n",
    "   #     norm_introduced_vars.append(norm_el)\n",
    "    #print(norm_introduced_vars)\n",
    "\n",
    "    #norm_bound_vars_fcg = []\n",
    "    #for el in bound_vars_fcg: \n",
    "    #    norm_el = int(el) / int(introduced_vars[-1])\n",
    "     #   norm_bound_vars_fcg.append(norm_el)\n",
    "    #print(norm_bound_vars_fcg)\n",
    "\n",
    "   # norm_bound_aes_fcg = []\n",
    "   # for el in bound_aes_fcg: \n",
    "   #     norm_el = int(el) / int(introduced_vars[-1])\n",
    "   #     norm_bound_aes_fcg.append(norm_el)\n",
    "    #print(norm_bound_aes_fcg)\n",
    "\n",
    "   # norm_bound_vars_irl = []\n",
    "   # for el in bound_vars_irl: \n",
    "   #     norm_el = int(el) / int(introduced_vars[-1])\n",
    "   #     norm_bound_vars_irl.append(norm_el)\n",
    "    #print(norm_bound_vars_irl)\n",
    "    \n",
    "   # norm_bound_slots_irl = []\n",
    "   # for el in bound_vars_irl: \n",
    "   #     norm_el = int(el) / int(introduced_vars[-1])\n",
    "   #     norm_bound_slots_irl.append(norm_el)\n",
    "    #print(norm_bound_vars_irl)\n",
    "    \n",
    "   # fig, ax = plt.subplots()\n",
    "   # y_pos = range(len(node_names))\n",
    "    #plt.xticks(y_pos, node_names, rotation=90)\n",
    "   # plt.figure()\n",
    "\n",
    "    lst = []\n",
    "    for i in range(0,len(bound_vars_fcg)):\n",
    "        lst.append(i)\n",
    "\n",
    "   # ax.bar(lst, norm_bound_vars_fcg, label='Answers from language', color=\"#1f77b4\")\n",
    "   # ax.bar(lst, norm_bound_vars_irl, bottom=norm_bound_vars_fcg , label='Answers from mental simulation', color=\"#2ca02c\")\n",
    "   # ax.bar(lst, norm_bound_slots_irl, bottom=[sum(x) for x in zip(norm_bound_vars_fcg, norm_bound_vars_irl)] , label='Answers from ontology', color=\"#ff7f0e\")\n",
    "   # ax.bar(lst, norm_bound_aes_fcg, bottom=[sum(x) for x in zip(norm_bound_vars_fcg, norm_bound_vars_irl,norm_bound_slots_irl)], label='Answers from discourse model', color=\"#d62728\")\n",
    "    #print(len(norm_introduced_vars))\n",
    "    #print(node_names)\n",
    "    #print(norm_introduced_vars)\n",
    "    \n",
    "   # for x in [61,74,87,96,111,117,131,len(introduced_vars)-1]:\n",
    "    for x in [61,111,len(introduced_vars)-1]:\n",
    "\n",
    "        total = sum(introduced_vars[:x])\n",
    "        bound_vars = {'Answers from language': sum(bound_vars_fcg[:x]), \n",
    "                     'Answers from mental simulation': sum(bound_vars_irl[:x]), \n",
    "                     'Answers from ontology' : sum(bound_slots_irl[:x]), \n",
    "                     'Answers from discourse model': sum(bound_aes_fcg[:x]),\n",
    "                     'Remaining questions': total - sum(bound_vars_fcg[:x]) - sum(bound_vars_irl[:x]) - sum(bound_slots_irl[:x]) - sum(bound_aes_fcg[:x])}\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(18.5, 10.5)\n",
    "        explode = (0, 0, 0, 0, 0.1) \n",
    "        ax.pie(bound_vars.values(), explode=explode,\n",
    "                 labels=None,autopct='%1.1f%%', textprops={'fontsize': 30})\n",
    "        ax.axis('equal')\n",
    "        #ax.plot(norm_introduced_vars, label='Total number of questions',color=\"black\", linewidth=1.0)\n",
    "\n",
    "        #ax.set_ylabel('Number of questions/answers')\n",
    "        #ax.set_xlabel('Steps in recipe execution')\n",
    "       # ax.set_title('Understanding Process')\n",
    "       # ax.legend(prop={\"size\":15})\n",
    "       #  \n",
    "       # ax.title.set_fontsize(20)\n",
    "       # ax.yaxis.label.set_fontsize(15)\n",
    "       # ax.xaxis.label.set_fontsize(15)\n",
    "        if x == 61: \n",
    "            plt.legend(labels=bound_vars.keys(),prop={'size': 20},loc='upper left')\n",
    "        \n",
    "        plt.savefig('pie-chart-' + str(x), bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_whole_norm_pie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_whole_questions_graph_not_norm_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_whole_questions_graph_not_norm_new():\n",
    "    data_dir = \"data-for-python-whole/\"\n",
    "    irl_filenames = ['irl-nodenames.csv','RECORD-ANCHORING-MICRO.csv', 'RECORD-QUESTIONS-IRL.csv', 'RECORD-SET-SLOTS.csv' , 'RECORD-SLOTS.csv']\n",
    "    fcg_filenames = ['fcg-nodenames.csv','RECORD-VARIABLES-BOUND-BY-GRAMMAR-MICRO.csv', 'RECORD-VARIABLES-INTRODUCED-BY-GRAMMAR-MICRO.csv','RECORD-ACCESSIBLE-ENTITIES-BOUND-BY-GRAMMAR-MICRO.csv']\n",
    "    dicts = files_to_dict(data_dir, irl_filenames, fcg_filenames)\n",
    "    dict_fcg = dicts[0]\n",
    "    dict_irl = dicts[1]\n",
    "    dict_irl = fix_length_aes(dict_irl)\n",
    "    final_dict = combine_irl_and_fcg_for_question_graph(dict_fcg,dict_irl)\n",
    "    print(final_dict)\n",
    "    for key in final_dict.keys(): \n",
    "        print(len(final_dict[key]))\n",
    "    plot_measures_questions_graph_new(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_measures_questions_graph_new(final_d):\n",
    "\n",
    "    flattened_dictionary = {}\n",
    "\n",
    "    for key in final_d.keys():\n",
    "        regular_list = final_d[key]\n",
    "        lst = [item for sublist in regular_list for item in sublist]\n",
    "        flattened_dictionary[key] = lst \n",
    "\n",
    "        \n",
    "    node_names = flattened_dictionary['nodenames']\n",
    "    bound_vars = cumSum([int(item) for item in flattened_dictionary['bound_vars']])\n",
    "    introduced_vars_fcg = cumSum([int(item) for item in flattened_dictionary['introduced_vars_fcg']])\n",
    "    introduced_vars_aes = cumSum([int(item) for item in flattened_dictionary['introduced_vars_aes']])\n",
    "    introduced_vars_slots = cumSum([int(item) for item in flattened_dictionary['introduced_vars_slots']])\n",
    "\n",
    "    #bound_vars_fcg = cumSum([int(item) for item in flattened_dictionary['bound_vars_fcg']])\n",
    "    #bound_aes_fcg = cumSum([int(item) for item in flattened_dictionary['bound_aes_fcg']])\n",
    "    #bound_vars_irl = cumSum([int(item) for item in flattened_dictionary['bound_vars_irl']])\n",
    "    #bound_slots_irl = cumSum([int(item) for item in flattened_dictionary['bound_slots_irl']])\n",
    "    \n",
    "    print('introduced_vars_fcg')\n",
    "    print(introduced_vars_fcg)\n",
    "    print('introduced_vars_aes')\n",
    "    print(introduced_vars_aes)\n",
    "    print('introduced_vars_slots')\n",
    "    print(introduced_vars_slots)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "    y_pos = range(len(node_names))\n",
    "    plt.xticks([])\n",
    "    plt.figure()\n",
    "\n",
    "    lst = []\n",
    "    for i in range(0,len(introduced_vars_fcg)):\n",
    "        lst.append(i)\n",
    "\n",
    "    ax.bar(lst, introduced_vars_fcg, label='Questions from language', color=\"#1f77b4\")\n",
    "    ax.bar(lst, introduced_vars_slots, bottom=introduced_vars_fcg , label='Questions from ontology', color=\"#ff7f0e\")\n",
    "    ax.bar(lst, introduced_vars_aes, bottom=[sum(x) for x in zip(introduced_vars_fcg, introduced_vars_slots)] , label='Questions from discourse model', color=\"#d62728\")\n",
    "    #ax.bar(lst, bound_aes_fcg, bottom=[sum(x) for x in zip(bound_vars_fcg, bound_vars_irl,bound_slots_irl)], label='Questions solved by discourse model')\n",
    "\n",
    "   # ax.plot(bound_vars, label='Total number of answers',color=\"black\", linewidth=2.0)\n",
    "\n",
    "    ax.set_ylabel('Number of questions')\n",
    "    ax.set_xlabel('Steps in recipe execution')\n",
    "    ax.legend(prop={\"size\":15})\n",
    "     \n",
    "    ax.title.set_fontsize(20)\n",
    "    ax.yaxis.label.set_fontsize(15)\n",
    "    ax.xaxis.label.set_fontsize(15)\n",
    "\n",
    "    plt.show()\n",
    "    plt.savefig('measures-for-understanding-aes-questions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = [\"Ingredients\", #226 grams butter, room temperature. 116 grams sugar. \\n4 grams vanilla extract, 4 grams almond extract, 340 grams flour, \\n112 grams almond flour, and 29 grams powdered sugar\", \n",
    "\"Beat the butter and the sugar together until light and fluffy.\",\n",
    "\"Add the vanilla and almond extracts and mix.\",\n",
    "\"Add the flour and the almond flour. \",\n",
    "\"Mix thoroughly.\",\n",
    "\"Take generous tablespoons of the dough and roll it into a small ball, \\nabout an inch in diameter, and then shape it into a crescent shape.\",\n",
    "\"Place onto a parchment paper lined baking sheet.\",\n",
    "\"Bake at 175 degrees Celsius for 15 - 20 minutes. \",\n",
    "\"Dust with powdered sugar.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### these pies \n",
    "\n",
    "data_dir = \"data-for-python-whole/\"\n",
    "irl_filenames = ['irl-nodenames.csv','RECORD-ANCHORING-MICRO.csv', 'RECORD-QUESTIONS-IRL.csv', 'RECORD-SET-SLOTS.csv' , 'RECORD-SLOTS.csv']\n",
    "fcg_filenames = ['fcg-nodenames.csv','RECORD-VARIABLES-BOUND-BY-GRAMMAR-MICRO.csv', 'RECORD-VARIABLES-INTRODUCED-BY-GRAMMAR-MICRO.csv','RECORD-ACCESSIBLE-ENTITIES-BOUND-BY-GRAMMAR-MICRO.csv']\n",
    "dicts = files_to_dict(data_dir, irl_filenames, fcg_filenames)\n",
    "dict_fcg = dicts[0]\n",
    "dict_irl = dicts[1]\n",
    "dict_irl = fix_length_aes(dict_irl)\n",
    "final_d = combine_irl_and_fcg(dict_fcg,dict_irl)\n",
    "\n",
    "flattened_dictionary = {}\n",
    "\n",
    "for key in final_d.keys():\n",
    "    regular_list = final_d[key]\n",
    "    lst = [item for sublist in regular_list for item in sublist]\n",
    "    flattened_dictionary[key] = lst \n",
    "\n",
    "node_names = flattened_dictionary['nodenames']\n",
    "introduced_vars = cumSum([int(item) for item in flattened_dictionary['introduced_vars']])\n",
    "bound_vars_fcg = cumSum([int(item) for item in flattened_dictionary['bound_vars_fcg']])\n",
    "bound_aes_fcg = cumSum([int(item) for item in flattened_dictionary['bound_aes_fcg']])\n",
    "bound_vars_irl = cumSum([int(item) for item in flattened_dictionary['bound_vars_irl']])\n",
    "bound_slots_irl = cumSum([int(item) for item in flattened_dictionary['bound_slots_irl']])\n",
    "\n",
    "lst = []\n",
    "for i in range(0,len(bound_vars_fcg)):\n",
    "    lst.append(i)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#fig.set_size_inches(5,5)\n",
    "plt.figure(figsize = (5, 15))\n",
    "\n",
    "explode = (0, 0, 0, 0, 0.1) \n",
    "x = [61,74,87,96,111,117,131,len(introduced_vars)-1]\n",
    "#i = 0\n",
    "def update(i): \n",
    "#for x in [61,111,len(introduced_vars)-1]:\n",
    "    ax.clear()\n",
    "    ax.axis('equal')\n",
    "    total = sum(introduced_vars[:x[i]])\n",
    "    bound_vars = {'Answers from language': sum(bound_vars_fcg[:x[i]]), \n",
    "                 'Answers from mental simulation': sum(bound_vars_irl[:x[i]]), \n",
    "                 'Answers from ontology' : sum(bound_slots_irl[:x[i]]), \n",
    "                 'Answers from discourse model': sum(bound_aes_fcg[:x[i]]),\n",
    "                 'Remaining questions': total - sum(bound_vars_fcg[:x[i]]) - sum(bound_vars_irl[:x[i]]) - sum(bound_slots_irl[:x[i]]) - sum(bound_aes_fcg[:x[i]])}\n",
    "    ax.pie(bound_vars.values(), explode=explode, labels=None,autopct='%1.1f%%', textprops={'fontsize': 10})\n",
    "    \n",
    "    ax.set_title(\"{}\".format(recipe[i]))\n",
    "ani = FuncAnimation(fig, update, frames=range(8),  repeat=False)\n",
    "\n",
    "f = \"questions-solved-compared-to-questions-introduced.gif\" \n",
    "ani.save(f, fps=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "animate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### these pies are cumulative\n",
    "\n",
    "data_dir = \"data-for-python-whole/\"\n",
    "irl_filenames = ['irl-nodenames.csv','RECORD-ANCHORING-MICRO.csv', 'RECORD-QUESTIONS-IRL.csv', 'RECORD-SET-SLOTS.csv' , 'RECORD-SLOTS.csv']\n",
    "fcg_filenames = ['fcg-nodenames.csv','RECORD-VARIABLES-BOUND-BY-GRAMMAR-MICRO.csv', 'RECORD-VARIABLES-INTRODUCED-BY-GRAMMAR-MICRO.csv','RECORD-ACCESSIBLE-ENTITIES-BOUND-BY-GRAMMAR-MICRO.csv']\n",
    "dicts = files_to_dict(data_dir, irl_filenames, fcg_filenames)\n",
    "dict_fcg = dicts[0]\n",
    "dict_irl = dicts[1]\n",
    "dict_irl = fix_length_aes(dict_irl)\n",
    "final_d = combine_irl_and_fcg(dict_fcg,dict_irl)\n",
    "\n",
    "flattened_dictionary = {}\n",
    "\n",
    "for key in final_d.keys():\n",
    "    regular_list = final_d[key]\n",
    "    lst = [item for sublist in regular_list for item in sublist]\n",
    "    flattened_dictionary[key] = lst \n",
    "\n",
    "node_names = flattened_dictionary['nodenames']\n",
    "introduced_vars = cumSum([int(item) for item in flattened_dictionary['introduced_vars']])\n",
    "bound_vars_fcg = cumSum([int(item) for item in flattened_dictionary['bound_vars_fcg']])\n",
    "bound_aes_fcg = cumSum([int(item) for item in flattened_dictionary['bound_aes_fcg']])\n",
    "bound_vars_irl = cumSum([int(item) for item in flattened_dictionary['bound_vars_irl']])\n",
    "bound_slots_irl = cumSum([int(item) for item in flattened_dictionary['bound_slots_irl']])\n",
    "\n",
    "\n",
    "bound_vars = {'Answers from language': 0, \n",
    "                 'Answers from mental simulation': 0, \n",
    "                 'Answers from ontology' :0, \n",
    "                 'Answers from discourse model': 0,\n",
    "                 'Remaining questions': 0}\n",
    "    \n",
    "\n",
    "lst = []\n",
    "for i in range(0,len(bound_vars_fcg)):\n",
    "    lst.append(i)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#fig.set_size_inches(5,5)\n",
    "plt.figure(figsize = (5, 15))\n",
    "\n",
    "explode = (0, 0, 0, 0, 0.1) \n",
    "x = [61,74,87,96,111,117,131,len(introduced_vars)]\n",
    "#i = 0\n",
    "\n",
    "def update(i): \n",
    "#for x in [61,111,len(introduced_vars)-1]:\n",
    "    ax.clear()\n",
    "    #ax.axis('equal')\n",
    "    #total = sum(introduced_vars[:x[i]])\n",
    "    total = sum(introduced_vars[:x[i]])\n",
    "    radius = sum(introduced_vars[:x[i]]) / sum(introduced_vars)\n",
    "    print(radius)\n",
    "    bound_vars = {'Answers from language': sum(bound_vars_fcg[:x[i]]), \n",
    "                 'Answers from mental simulation': sum(bound_vars_irl[:x[i]]), \n",
    "                'Answers from ontology' : sum(bound_slots_irl[:x[i]]), \n",
    "                 'Answers from discourse model': sum(bound_aes_fcg[:x[i]]),\n",
    "                 'Remaining questions': total - sum(bound_vars_fcg[:x[i]]) - sum(bound_vars_irl[:x[i]]) -sum(bound_slots_irl[:x[i]]) - sum(bound_aes_fcg[:x[i]])}\n",
    "    \n",
    "    ax.pie(bound_vars.values(), explode=None, labels=None,autopct='%1.1f%%', radius=radius, textprops={'fontsize': 10})\n",
    "    \n",
    "    ax.set_title(\"{}\".format(recipe[i]))\n",
    "    #if x == 61:\n",
    "    ax.legend(labels = bound_vars.keys(), loc=\"upper left\")\n",
    "\n",
    "    print(\"{}\".format(recipe[i]))\n",
    "\n",
    "#plt.legend(labels=bound_vars.keys(),loc='upper left')\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=range(8),  repeat=False)\n",
    "f = \"test-cumulative.gif\" \n",
    "ani.save(f, fps=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### these pies \n",
    "\n",
    "data_dir = \"data-for-python-whole/\"\n",
    "irl_filenames = ['irl-nodenames.csv','RECORD-ANCHORING-MICRO.csv', 'RECORD-QUESTIONS-IRL.csv', 'RECORD-SET-SLOTS.csv' , 'RECORD-SLOTS.csv']\n",
    "fcg_filenames = ['fcg-nodenames.csv','RECORD-VARIABLES-BOUND-BY-GRAMMAR-MICRO.csv', 'RECORD-VARIABLES-INTRODUCED-BY-GRAMMAR-MICRO.csv','RECORD-ACCESSIBLE-ENTITIES-BOUND-BY-GRAMMAR-MICRO.csv']\n",
    "dicts = files_to_dict(data_dir, irl_filenames, fcg_filenames)\n",
    "dict_fcg = dicts[0]\n",
    "dict_irl = dicts[1]\n",
    "dict_irl = fix_length_aes(dict_irl)\n",
    "final_d = combine_irl_and_fcg(dict_fcg,dict_irl)\n",
    "\n",
    "flattened_dictionary = {}\n",
    "\n",
    "for key in final_d.keys():\n",
    "    regular_list = final_d[key]\n",
    "    lst = [item for sublist in regular_list for item in sublist]\n",
    "    flattened_dictionary[key] = lst \n",
    "\n",
    "node_names = flattened_dictionary['nodenames']\n",
    "introduced_vars = [int(item) for item in flattened_dictionary['introduced_vars']]\n",
    "bound_vars_fcg = [int(item) for item in flattened_dictionary['bound_vars_fcg']]\n",
    "bound_aes_fcg = [int(item) for item in flattened_dictionary['bound_aes_fcg']]\n",
    "bound_vars_irl = [int(item) for item in flattened_dictionary['bound_vars_irl']]\n",
    "bound_slots_irl = [int(item) for item in flattened_dictionary['bound_slots_irl']]\n",
    "\n",
    "\n",
    "\n",
    "bound_vars = {'Answers from language': 0, \n",
    "              'Answers from mental simulation': 0, \n",
    "                 'Answers from ontology' :0, \n",
    "                 'Answers from discourse model': 0,\n",
    "                 'Remaining questions': 0}\n",
    "    \n",
    "\n",
    "lst = []\n",
    "for i in range(0,len(bound_vars_fcg)):\n",
    "    lst.append(i)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.figure(figsize = (5, 15))\n",
    "\n",
    "explode = (0, 0, 0, 0, 0.1) \n",
    "x = [61,74,87,96,111,117,131,len(introduced_vars)]\n",
    "#i = 0\n",
    "\n",
    "def update(i): \n",
    "    ax.clear()\n",
    "    print(x[i-1])\n",
    "    total = sum(introduced_vars[x[i-1]:x[i]])\n",
    "    bound_vars = {'Answers from language': sum(bound_vars_fcg[x[i-1]:x[i]]), \n",
    "                  'Answers from mental simulation': sum(bound_vars_irl[x[i-1]:x[i]]), \n",
    "                  'Answers from ontology' : sum(bound_slots_irl[x[i-1]:x[i]]), \n",
    "                  'Answers from discourse model': sum(bound_aes_fcg[x[i-1]:x[i]]),\n",
    "                  'Remaining questions': total - sum(bound_vars_fcg[x[i-1]:x[i]]) - sum(bound_vars_irl[x[i-1]:x[i]]) -sum(bound_slots_irl[x[i-1]:x[i]]) - sum(bound_aes_fcg[x[i-1]:x[i]])}\n",
    "    \n",
    "    ax.pie(bound_vars.values(), explode=None, labels=None,autopct='%1.1f%%', radius=1, textprops={'fontsize': 10})\n",
    "    \n",
    "    ax.set_title(\"{}\".format(recipe[i]))\n",
    "   # ax.legend(labels = bound_vars.keys(), loc=\"lower right\")\n",
    "\n",
    "    print(\"{}\".format(recipe[i]))\n",
    "\n",
    "#plt.legend(labels=bound_vars.keys(),loc='lower right')\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=range(8),  repeat=False)\n",
    "f = \"test.gif\" \n",
    "ani.save(f, fps=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### these pies are cumulative\n",
    "\n",
    "data_dir = \"data-for-python/\"\n",
    "irl_filenames = ['irl-nodenames.csv','RECORD-ANCHORING-MICRO.csv', 'RECORD-QUESTIONS-IRL.csv', 'RECORD-SET-SLOTS.csv' , 'RECORD-SLOTS.csv']\n",
    "fcg_filenames = ['fcg-nodenames.csv','RECORD-VARIABLES-BOUND-BY-GRAMMAR-MICRO.csv', 'RECORD-VARIABLES-INTRODUCED-BY-GRAMMAR-MICRO.csv','RECORD-ACCESSIBLE-ENTITIES-BOUND-BY-GRAMMAR-MICRO.csv']\n",
    "dicts = files_to_dict(data_dir, irl_filenames, fcg_filenames)\n",
    "dict_fcg = dicts[0]\n",
    "dict_irl = dicts[1]\n",
    "dict_irl = fix_length_aes(dict_irl)\n",
    "final_d = combine_irl_and_fcg(dict_fcg,dict_irl)\n",
    "\n",
    "flattened_dictionary = {}\n",
    "\n",
    "for key in final_d.keys():\n",
    "    regular_list = final_d[key]\n",
    "    lst = [item for sublist in regular_list for item in sublist]\n",
    "    flattened_dictionary[key] = lst \n",
    "\n",
    "node_names = flattened_dictionary['nodenames']\n",
    "print(node_names)\n",
    "introduced_vars = cumSum([int(item) for item in flattened_dictionary['introduced_vars']])\n",
    "bound_vars_fcg = cumSum([int(item) for item in flattened_dictionary['bound_vars_fcg']])\n",
    "bound_aes_fcg = cumSum([int(item) for item in flattened_dictionary['bound_aes_fcg']])\n",
    "bound_vars_irl = cumSum([int(item) for item in flattened_dictionary['bound_vars_irl']])\n",
    "bound_slots_irl = cumSum([int(item) for item in flattened_dictionary['bound_slots_irl']])\n",
    "\n",
    "\n",
    "bound_vars = {'Answers from language': 0, \n",
    "                 'Answers from mental simulation': 0, \n",
    "                 'Answers from ontology' :0, \n",
    "                 'Answers from discourse model': 0,\n",
    "                 'Remaining questions': 0}\n",
    "    \n",
    "\n",
    "lst = []\n",
    "for i in range(0,len(bound_vars_fcg)):\n",
    "    lst.append(i)\n",
    "\n",
    "\n",
    "recipe = [\"Ingredients\", #226 grams butter, room temperature. 116 grams sugar. \\n4 grams vanilla extract, 4 grams almond extract, 340 grams flour, \\n112 grams almond flour, and 29 grams powdered sugar\", \n",
    "\"Beat the butter and the sugar together until light and fluffy.\",\n",
    "\"Add the vanilla and almond extracts and mix.\",\n",
    "\"Add the flour and the almond flour. \",\n",
    "\"Mix thoroughly.\",\n",
    "\"Take generous tablespoons of the dough and roll it into a small ball, \\nabout an inch in diameter, and then shape it into a crescent shape.\",\n",
    "\"Place onto a parchment paper lined baking sheet.\",\n",
    "\"Bake at 175 degrees Celsius for 15 - 20 minutes. \",\n",
    "\"Dust with powdered sugar.\"]\n",
    " \n",
    "x = [61,74,87,96,111,117,131,len(introduced_vars)]\n",
    "#i = 0\n",
    "\n",
    "for x in [61,74,87,96,111,117,131,len(introduced_vars)]:\n",
    "#for x in [61,111,len(introduced_vars)-1]:\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(5,5)\n",
    "    #plt.figure(figsize = (15, 15))\n",
    "    explode = (0, 0, 0, 0, 0.1)\n",
    "    #ax.clear()\n",
    "    #ax.axis('equal')\n",
    "    #total = sum(introduced_vars[:x[i]])\n",
    "    total = sum(introduced_vars[:x])\n",
    "    radius = sum(introduced_vars[:x]) / sum(introduced_vars)\n",
    "    print(radius)\n",
    "    bound_vars = {'Answers from language': sum(bound_vars_fcg[:x]), \n",
    "                 'Answers from mental simulation': sum(bound_vars_irl[:x]), \n",
    "                'Answers from ontology' : sum(bound_slots_irl[:x]), \n",
    "                 'Answers from discourse model': sum(bound_aes_fcg[:x]),\n",
    "                 'Remaining questions': total - sum(bound_vars_fcg[:x]) - sum(bound_vars_irl[:x]) - sum(bound_slots_irl[:x]) - sum(bound_aes_fcg[:x])}\n",
    "    \n",
    "    if x == 61:\n",
    "        pctdistance = 1.5\n",
    "    else:\n",
    "        pctdistance = 0.6\n",
    "    \n",
    "    ax.pie(bound_vars.values(), explode=None, labels=None,  pctdistance =pctdistance, autopct='%1.1f%%', radius=radius, textprops={'fontsize': 10})\n",
    "    \n",
    "    if x == 61: \n",
    "        ax.legend(labels=bound_vars.keys(),prop={'size': 10},loc='upper left')\n",
    "        \n",
    "    plt.savefig('pie-chart-' + str(x) + '.pdf' , bbox_inches='tight')\n",
    "    \n",
    "\n",
    "#plt.legend(labels=bound_vars.keys(),loc='upper left')\n",
    "    plt.show()\n",
    "#ani = FuncAnimation(fig, update, frames=range(8),  repeat=False)\n",
    "#f = \"test-cumulative.gif\" \n",
    "#ani.save(f, fps=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for x in [61,111,len(introduced_vars)-1]:\n",
    "\n",
    "        total = sum(introduced_vars[:x])\n",
    "        bound_vars = {'Answers from language': sum(bound_vars_fcg[:x]), \n",
    "                     'Answers from mental simulation': sum(bound_vars_irl[:x]), \n",
    "                     'Answers from ontology' : sum(bound_slots_irl[:x]), \n",
    "                     'Answers from discourse model': sum(bound_aes_fcg[:x]),\n",
    "                     'Remaining questions': total - sum(bound_vars_fcg[:x]) - sum(bound_vars_irl[:x]) - sum(bound_slots_irl[:x]) - sum(bound_aes_fcg[:x])}\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches(18.5, 10.5)\n",
    "        explode = (0, 0, 0, 0, 0.1) \n",
    "        ax.pie(bound_vars.values(), explode=explode,\n",
    "                 labels=None,autopct='%1.1f%%', textprops={'fontsize': 30})\n",
    "        ax.axis('equal')\n",
    "        #ax.plot(norm_introduced_vars, label='Total number of questions',color=\"black\", linewidth=1.0)\n",
    "\n",
    "        #ax.set_ylabel('Number of questions/answers')\n",
    "        #ax.set_xlabel('Steps in recipe execution')\n",
    "       # ax.set_title('Understanding Process')\n",
    "       # ax.legend(prop={\"size\":15})\n",
    "       #  \n",
    "       # ax.title.set_fontsize(20)\n",
    "       # ax.yaxis.label.set_fontsize(15)\n",
    "       # ax.xaxis.label.set_fontsize(15)\n",
    "        if x == 61: \n",
    "            plt.legend(labels=bound_vars.keys(),prop={'size': 20},loc='upper left')\n",
    "        \n",
    "        plt.savefig('pie-chart-' + str(x), bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "irl_filenames = ['irl-nodenames.csv','QUESTIONS-INTRODUCED-BY-DISCOURSE.csv', 'QUESTIONS-INTRODUCED-BY-MENTAL-SIMULATION.csv', 'QUESTIONS-INTRODUCED-BY-ONTOLOGY.csv']\n",
    "fcg_filenames = ['fcg-nodenames.csv', 'QUESTIONS-INTRODUCED-BY-GRAMMAR.csv']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "d_irl = {}\n",
    "for file_name in os.listdir(data_dir): \n",
    "        f = os.path.join(data_dir, file_name)\n",
    "        file = open(f)\n",
    "        csv_reader = csv.reader(file, delimiter=' ')\n",
    "        #print(file_name)\n",
    "        lst = []\n",
    "        irl_lst = []\n",
    "        if file_name in fcg_filenames : \n",
    "            for row in csv_reader: \n",
    "                lst.append(row) \n",
    "                d[file_name] = lst\n",
    "        elif file_name in irl_filenames: \n",
    "            for row in csv_reader: \n",
    "                irl_lst.append(row) \n",
    "                d_irl[file_name] = irl_lst\n",
    "print(d)\n",
    "print(d_irl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodenames = []\n",
    "for irl_names, fcg_names in zip(d_irl['irl-nodenames.csv'], d['fcg-nodenames.csv']):\n",
    "    nodenames.append(irl_names)\n",
    "    nodenames.append(fcg_names)\n",
    "print(nodenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_grammar = []\n",
    "for irl_names, questions_grammar in zip(d_irl['irl-nodenames.csv'], d['QUESTIONS-INTRODUCED-BY-GRAMMAR.csv']):\n",
    "    q_grammar.append([0] * len(irl_names))\n",
    "    q_grammar.append(questions_grammar)\n",
    "print(q_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_mental = []\n",
    "for fcg_names, questions_mental in zip(d['fcg-nodenames.csv'], d_irl['QUESTIONS-INTRODUCED-BY-MENTAL-SIMULATION.csv']):\n",
    "    q_mental.append(questions_mental)\n",
    "    q_mental.append([0] * len(fcg_names))\n",
    "    \n",
    "print(q_mental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_discourse = []\n",
    "for fcg_names, questions_discourse in zip(d['fcg-nodenames.csv'], d_irl['QUESTIONS-INTRODUCED-BY-DISCOURSE.csv']):\n",
    "    q_discourse.append(questions_discourse)\n",
    "    q_discourse.append([0] * len(fcg_names))\n",
    "    \n",
    "print(q_discourse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ontology = []\n",
    "for fcg_names, questions_ontology in zip(d['fcg-nodenames.csv'], d_irl['QUESTIONS-INTRODUCED-BY-ONTOLOGY.csv']):\n",
    "    q_ontology.append(questions_ontology)\n",
    "    q_ontology.append([0] * len(fcg_names))\n",
    "    \n",
    "print(q_ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b92396f9b56f1350fabc55aa1a1105a84f42df9046600cf5093bdb969faef3c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
